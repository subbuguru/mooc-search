{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "00e1e0ee-b46b-4725-9370-6824612666f0",
    "_uuid": "40391401-2b4c-4df7-a618-89fadd5fe087",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Install NLTK and other packages\n",
    "!pip list | grep nltk\n",
    "! pip install -U kaleido\n",
    "!pip install sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Unzip per this stackoverflow: https://stackoverflow.com/questions/73849624/getting-error-while-submitting-notebook-on-kaggle-even-after-importing-nltk-libr\n",
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8b82a793-ab1b-4d0c-8bb8-f1727296069f",
    "_uuid": "e1a06785-20c6-421e-9b5d-090f01909de8",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data cleaning and normalization\n",
    "\n",
    "# Normalize/clean course data to the name, topic, link, text format for now\n",
    "\n",
    "dataMit = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\")\n",
    "dataMit.columns = map(str.lower, dataMit.columns)\n",
    "dataMit.rename(columns={\"name \": \"name\"}, inplace=True)\n",
    "dataMit.rename(columns={\"course link\": \"link\"}, inplace=True)\n",
    "dataMit[\"text\"] = dataMit[\"name\"] + \" \" + dataMit[\"topic\"]\n",
    "dataMit[\"provider\"] = \"Massachussets Institute of Technology\"\n",
    "dataMit = dataMit[[\"name\", \"topic\", \"link\", \"provider\", \"text\"]]\n",
    "\n",
    "\n",
    "dataHarvard = pd.read_csv(\n",
    "    \"/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\"\n",
    ")\n",
    "dataHarvard.columns = map(str.lower, dataHarvard.columns)\n",
    "dataHarvard.rename(columns={\"link to course\": \"link\", \"about\": \"topic\"}, inplace=True)\n",
    "dataHarvard = dataHarvard[dataHarvard[\"price\"] == \"Free\"]\n",
    "dataHarvard[\"text\"] = dataHarvard[\"name\"] + \" \" + dataHarvard[\"topic\"]\n",
    "dataHarvard[\"provider\"] = \"Harvard University\"\n",
    "dataHarvard = dataHarvard[[\"name\", \"topic\", \"link\", \"provider\", \"text\"]]\n",
    "\n",
    "\n",
    "dataEdx = pd.read_csv(\"/kaggle/input/edx-courses-dataset-2021/EdX.csv\")\n",
    "dataEdx.columns = map(str.lower, dataEdx.columns)\n",
    "dataEdx[\"topic\"] = dataEdx[\"about\"] + \". \" + dataEdx[\"course description\"]\n",
    "dataEdx[\"provider\"] = \"edX - \" + dataEdx[\"university\"]\n",
    "dataEdx[\"text\"] = dataEdx[\"name\"] + \" \" + dataEdx[\"topic\"]\n",
    "dataEdx = dataEdx[[\"name\", \"topic\", \"link\", \"provider\", \"text\"]]\n",
    "\n",
    "\n",
    "dataUdemy = pd.read_csv(\n",
    "    \"/kaggle/input/udemy-course-dataset-categories-ratings-and-trends/udemy_courses.csv\"\n",
    ")\n",
    "dataUdemy.columns = map(str.lower, dataUdemy.columns)\n",
    "dataUdemy.rename(\n",
    "    columns={\n",
    "        \"title\": \"name\",\n",
    "        \"headline\": \"topic\",\n",
    "        \"url\": \"link\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "# only keep free courses\n",
    "dataUdemy = dataUdemy[dataUdemy[\"is_paid\"] == False]\n",
    "# Since Udemy courses are user generated, filter only courses with rating over 4.5\n",
    "dataUdemy[\"provider\"] = \"Udemy\"\n",
    "dataUdemy = dataUdemy[dataUdemy[\"rating\"] > 4.5]\n",
    "dataUdemy[\"text\"] = dataUdemy[\"name\"] + \" \" + dataUdemy[\"topic\"]\n",
    "dataUdemy = dataUdemy[[\"name\", \"topic\", \"link\", \"provider\", \"text\"]]\n",
    "\n",
    "\n",
    "dataCoursera = pd.read_csv(\"/kaggle/input/coursera-free-courses-dataset/coursera.csv\")\n",
    "dataCoursera.rename(\n",
    "    columns={\n",
    "        \"title\": \"name\",\n",
    "        \"skills\": \"topic\",\n",
    "        \"url\": \"link\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "dataCoursera = dataCoursera[dataCoursera[\"price\"] == \"Free\"]\n",
    "dataCoursera[\"text\"] = (\n",
    "    dataCoursera[\"name\"]\n",
    "    + \" \"\n",
    "    + np.where(pd.notna(dataCoursera[\"topic\"]), dataCoursera[\"topic\"], \"\")\n",
    ")\n",
    "\n",
    "dataCoursera[\"provider\"] = \"Coursera - \" + dataCoursera[\"course_by\"]\n",
    "dataCoursera = dataCoursera[[\"name\", \"topic\", \"link\", \"provider\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9554aa35-ecf5-472f-8dde-cc926b054f7b",
    "_uuid": "71ebb7ec-b2d9-4370-91a2-c3a0d02b14c1",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    lemma = WordNetLemmatizer()  # lemmatizer\n",
    "    text = re.sub(\"[^A-Za-z0-9 ]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)  # look into this tokenization\n",
    "    tokens = [\n",
    "        lemma.lemmatize(word)\n",
    "        for word in tokens  # lemmatize words and remove stopwords\n",
    "        if word not in stopwords.words(\"english\")\n",
    "    ]\n",
    "    return \" \".join(tokens)  # SBERT rrequires joined tokens\n",
    "\n",
    "\n",
    "# Combine and clean data\n",
    "data = pd.concat([dataUdemy, dataMit, dataHarvard, dataEdx, dataCoursera])\n",
    "data[\"cleaned_text\"] = data[\"text\"].apply(\n",
    "    clean_text\n",
    ")  # Add clean text column to dataframe\n",
    "\n",
    "# Drop non-english courses\n",
    "indices_to_drop = [\n",
    "    index\n",
    "    for index, row in data.iterrows()\n",
    "    if bool(\n",
    "        re.search(\n",
    "            r\"[^\\x00-\\x7F\\u2000-\\u206F\\u2600-\\u26FF\\u2700-\\u27BF]\", str(row[\"text\"])\n",
    "        )\n",
    "    )\n",
    "]\n",
    "data = data.drop(indices_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d6eb8190-4228-468b-9778-44e837d32fbc",
    "_uuid": "074b07b4-99ea-418e-b2cb-87ad6215114e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Get a list of the document embedding vector for each sentence in the cleaned text data. The indices will be aligned with the original course rows in dataframe\n",
    "document_embeddings = model.encode(data[\"cleaned_text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "37c49b4e-c83a-4c1e-8a26-2d0dee61aaf8",
    "_uuid": "fc0ed95c-e266-4e88-b9a2-221e34dba717",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Export a csv with embeddings for fastapi\n",
    "data = data[[\"name\", \"topic\", \"link\", \"provider\"]]\n",
    "data.to_csv(\"courses.csv\", index=False)\n",
    "embeddings = pd.DataFrame(document_embeddings)\n",
    "embeddings.to_csv(\"embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "46a977e5-fbcf-4a31-9377-65b0269f89cb",
    "_uuid": "3e1d1d42-84b4-4e9a-be9c-6f3c59b6fed2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Use previous functions to process user input into vector and use cosine\n",
    "# Cosine Similarity to find the most related courses\n",
    "# removed document_embeddings, data, model, top_n=5 as it was unnecessary abstraction layer\n",
    "\n",
    "\n",
    "def recommend_courses(user_input: str, top_n=5) -> str:\n",
    "    \"\"\"Converts the user input to an embedding vector and compares it to list of courses embeddings,\n",
    "    returning the 5 with the highest cosine similarity.\"\"\"\n",
    "    cleaned_input = clean_text(user_input)\n",
    "    input_embedding = model.encode([cleaned_input])  # Model must be initialized\n",
    "    similarities = cosine_similarity(input_embedding, document_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "    recommendations = data.iloc[top_indices][[\"name\", \"topic\", \"link\", \"provider\"]]\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "user_input = \"Python\"\n",
    "recommendations = recommend_courses(user_input)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1868643,
     "sourceId": 3051937,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2423448,
     "sourceId": 5103339,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5456599,
     "sourceId": 9279572,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6138541,
     "sourceId": 9976645,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 225262,
     "modelInstanceId": 204042,
     "sourceId": 256574,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
