{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3051937,"sourceType":"datasetVersion","datasetId":1868643},{"sourceId":5103339,"sourceType":"datasetVersion","datasetId":2423448},{"sourceId":9279572,"sourceType":"datasetVersion","datasetId":5456599},{"sourceId":9976645,"sourceType":"datasetVersion","datasetId":6138541},{"sourceId":256574,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":204042,"modelId":225262}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Setup\n\n# Install NLTK and other packages\n!pip list | grep nltk\n! pip install -U kaleido\n!pip install sentence-transformers\n\nfrom sentence_transformers import SentenceTransformer\nimport pandas as pd\nimport numpy as np\nfrom gensim.models import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity \nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nimport re\nimport nltk\n\n\n\n\nnltk.download('punkt')  \nnltk.download('wordnet')  \n\n# Unzip per this stackoverflow: https://stackoverflow.com/questions/73849624/getting-error-while-submitting-notebook-on-kaggle-even-after-importing-nltk-libr\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"_uuid":"11872ad3-929a-453c-a9a8-212f3f47cff9","_cell_guid":"ad38c9bc-2362-4c5f-bb22-04197c45c913","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T03:36:40.093458Z","iopub.execute_input":"2025-03-19T03:36:40.093778Z","iopub.status.idle":"2025-03-19T03:37:34.809991Z","shell.execute_reply.started":"2025-03-19T03:36:40.093757Z","shell.execute_reply":"2025-03-19T03:37:34.809167Z"}},"outputs":[{"name":"stdout","text":"nltk                               3.2.4\nCollecting kaleido\n  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\nDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: kaleido\nSuccessfully installed kaleido-0.2.1\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Data cleaning and normalization\n\n# Normalize/clean course data to the name, topic, link, text format for now\n\ndataMit = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\")\ndataMit.columns = map(str.lower, dataMit.columns)\ndataMit.rename(columns={'name ': 'name'}, inplace=True)\ndataMit.rename(columns={'course link': 'link'}, inplace=True)\ndataMit['text'] = dataMit['name'] + \" \" + dataMit['topic'] \ndataMit['provider'] = 'Massachussets Institute of Technology'\ndataMit = dataMit[['name', 'topic', 'link', 'provider', 'text']]\n\n\ndataHarvard = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\")\ndataHarvard.columns = map(str.lower, dataHarvard.columns)\ndataHarvard.rename(columns={'link to course': 'link', 'about': 'topic'}, inplace=True)\ndataHarvard = dataHarvard[dataHarvard['price'] == 'Free']\ndataHarvard['text'] = dataHarvard['name'] + \" \" + dataHarvard['topic'] \ndataHarvard['provider'] = 'Harvard University'\ndataHarvard = dataHarvard[['name', 'topic', 'link', 'provider', 'text']]\n\n\ndataEdx = pd.read_csv(\"/kaggle/input/edx-courses-dataset-2021/EdX.csv\")\ndataEdx.columns = map(str.lower, dataEdx.columns)\ndataEdx[\"topic\"] = dataEdx['about'] + '. ' + dataEdx['course description']\ndataEdx[\"provider\"] = 'edX - ' + dataEdx['university']\ndataEdx['text'] = dataEdx['name'] + \" \" + dataEdx[\"topic\"]\ndataEdx = dataEdx[['name', 'topic', 'link', 'provider', 'text']]\n\n\ndataUdemy = pd.read_csv(\"/kaggle/input/udemy-course-dataset-categories-ratings-and-trends/udemy_courses.csv\")\ndataUdemy.columns = map(str.lower, dataUdemy.columns)\ndataUdemy.rename(columns={\n    'title': 'name',\n    'headline': 'topic',\n    'url': 'link',\n}, inplace=True)\n# only keep free courses\ndataUdemy = dataUdemy[dataUdemy['is_paid'] == False]\n# Since Udemy courses are user generated, filter only courses with rating over 4.5\ndataUdemy['provider'] = 'Udemy'\ndataUdemy = dataUdemy[dataUdemy['rating'] > 4.5 ]\ndataUdemy['text'] = dataUdemy['name'] + \" \" + dataUdemy['topic']\ndataUdemy = dataUdemy[['name', 'topic', 'link', 'provider', 'text']]\n\n\ndataCoursera = pd.read_csv(\"/kaggle/input/coursera-free-courses-dataset/coursera.csv\")\ndataCoursera.rename(columns={\n    'title': 'name',\n    'skills': 'topic',\n    'url': 'link',\n}, inplace=True)\ndataCoursera = dataCoursera[dataCoursera['price'] == 'Free']\ndataCoursera['text'] = dataCoursera['name'] + \" \" + np.where(pd.notna(dataCoursera['topic']), dataCoursera['topic'], \"\")\n\ndataCoursera['provider'] = 'Coursera - ' + dataCoursera['course_by']\ndataCoursera = dataCoursera[['name', 'topic', 'link', 'provider', 'text']]","metadata":{"_uuid":"96a00073-5fdf-4e9c-8ae4-a2aac33628dd","_cell_guid":"c5885aea-ad3a-4df3-8c01-65d9d1225cf1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T03:37:50.697808Z","iopub.execute_input":"2025-03-19T03:37:50.699189Z","iopub.status.idle":"2025-03-19T03:37:55.178075Z","shell.execute_reply.started":"2025-03-19T03:37:50.699156Z","shell.execute_reply":"2025-03-19T03:37:55.177385Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def clean_text(text):\n    lemma = WordNetLemmatizer() # lemmatizer\n    text = re.sub(\"[^A-Za-z0-9 ]\", \"\", text)\n    text = text.lower()\n    tokens = word_tokenize(text) # look into this tokenization\n    tokens = [lemma.lemmatize(word) for word in tokens # lemmatize words and remove stopwords \n                if word not in stopwords.words(\"english\")]\n    return \" \".join(tokens) # SBERT rrequires joined tokens\n\n#Combine and clean data\ndata = pd.concat([dataUdemy, dataMit, dataHarvard, dataEdx, dataCoursera])\ndata['cleaned_text'] = data['text'].apply(clean_text) # Add clean text column to dataframe\n\n# Drop non-english courses\nindices_to_drop = [index for index, row in data.iterrows() if bool(re.search(r'[^\\x00-\\x7F\\u2000-\\u206F\\u2600-\\u26FF\\u2700-\\u27BF]', str(row['text'])))]\ndata = data.drop(indices_to_drop)\n\ndata.head()","metadata":{"_uuid":"703c98e4-4486-4f12-a888-a3ffb4061644","_cell_guid":"5db69b4c-1811-4507-8f4c-41fa19d87acc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T03:37:59.320762Z","iopub.execute_input":"2025-03-19T03:37:59.321091Z","iopub.status.idle":"2025-03-19T03:38:25.489127Z","shell.execute_reply.started":"2025-03-19T03:37:59.321042Z","shell.execute_reply":"2025-03-19T03:38:25.488272Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                    name  \\\n26443                           Stock Market Foundations   \n26445  The Complete Course On Understanding Blockchai...   \n26446  Bitcoin or How I Learned to Stop Worrying and ...   \n26448  Blockchain cryptocurrency course 101 for absol...   \n26449  Trading Options For Consistent Returns: Option...   \n\n                                                   topic  \\\n26443  The Market isn't a Mystery, It’s a Playground....   \n26445  A Beginner's Guide to Authentic Knowledge on B...   \n26446  The definitive guide to understand what the bi...   \n26448  A complete guide to anyone who wants to really...   \n26449                     The Foundation For Consistency   \n\n                                                    link provider  \\\n26443  https://www.udemy.com/course/how-to-invest-in-...    Udemy   \n26445  https://www.udemy.com/course/understanding-blo...    Udemy   \n26446  https://www.udemy.com/course/bitcoin-or-how-i-...    Udemy   \n26448  https://www.udemy.com/course/blockchain-crypto...    Udemy   \n26449  https://www.udemy.com/course/trading-options-f...    Udemy   \n\n                                                    text  \\\n26443  Stock Market Foundations The Market isn't a My...   \n26445  The Complete Course On Understanding Blockchai...   \n26446  Bitcoin or How I Learned to Stop Worrying and ...   \n26448  Blockchain cryptocurrency course 101 for absol...   \n26449  Trading Options For Consistent Returns: Option...   \n\n                                            cleaned_text  \n26443  stock market foundation market isnt mystery pl...  \n26445  complete course understanding blockchain techn...  \n26446  bitcoin learned stop worrying love crypto defi...  \n26448  blockchain cryptocurrency course 101 absolute ...  \n26449  trading option consistent return option basic ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n      <th>provider</th>\n      <th>text</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26443</th>\n      <td>Stock Market Foundations</td>\n      <td>The Market isn't a Mystery, It’s a Playground....</td>\n      <td>https://www.udemy.com/course/how-to-invest-in-...</td>\n      <td>Udemy</td>\n      <td>Stock Market Foundations The Market isn't a My...</td>\n      <td>stock market foundation market isnt mystery pl...</td>\n    </tr>\n    <tr>\n      <th>26445</th>\n      <td>The Complete Course On Understanding Blockchai...</td>\n      <td>A Beginner's Guide to Authentic Knowledge on B...</td>\n      <td>https://www.udemy.com/course/understanding-blo...</td>\n      <td>Udemy</td>\n      <td>The Complete Course On Understanding Blockchai...</td>\n      <td>complete course understanding blockchain techn...</td>\n    </tr>\n    <tr>\n      <th>26446</th>\n      <td>Bitcoin or How I Learned to Stop Worrying and ...</td>\n      <td>The definitive guide to understand what the bi...</td>\n      <td>https://www.udemy.com/course/bitcoin-or-how-i-...</td>\n      <td>Udemy</td>\n      <td>Bitcoin or How I Learned to Stop Worrying and ...</td>\n      <td>bitcoin learned stop worrying love crypto defi...</td>\n    </tr>\n    <tr>\n      <th>26448</th>\n      <td>Blockchain cryptocurrency course 101 for absol...</td>\n      <td>A complete guide to anyone who wants to really...</td>\n      <td>https://www.udemy.com/course/blockchain-crypto...</td>\n      <td>Udemy</td>\n      <td>Blockchain cryptocurrency course 101 for absol...</td>\n      <td>blockchain cryptocurrency course 101 absolute ...</td>\n    </tr>\n    <tr>\n      <th>26449</th>\n      <td>Trading Options For Consistent Returns: Option...</td>\n      <td>The Foundation For Consistency</td>\n      <td>https://www.udemy.com/course/trading-options-f...</td>\n      <td>Udemy</td>\n      <td>Trading Options For Consistent Returns: Option...</td>\n      <td>trading option consistent return option basic ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Initialize the model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Get a list of the document embedding vector for each sentence in the cleaned text data. The indices will be aligned with the original course rows in dataframe\ndocument_embeddings = model.encode(data['cleaned_text'].tolist())","metadata":{"_uuid":"413030c0-e87c-45cb-8889-5563c6bcd487","_cell_guid":"c6791a3a-7829-469a-906e-710b1bad80e4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T03:38:29.120758Z","iopub.execute_input":"2025-03-19T03:38:29.121046Z","iopub.status.idle":"2025-03-19T03:38:35.727954Z","shell.execute_reply.started":"2025-03-19T03:38:29.121025Z","shell.execute_reply":"2025-03-19T03:38:35.727320Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f79867a7b9354891840da4bbe387c192"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b2d6985f903473a95c1cd8b05804a92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d9f61a08c724dfeb12319209f58f536"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63a54bcab73147f5bd0cc415635ad133"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b27bf33c351640ae9532a60068794d30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"888c97fa00f04594af828ea49ebd863b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a040b0c13ec49558c110ad1b696589f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e083041262c4f278b298090959702a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a4d8abb52e542a2bb5f9a5ae1af031a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1750bb8239b4a96ad348b3648f90728"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cd48c5a07c346cd91ed1191e1f73b6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/164 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dacc3156577241ceba783d3fb2aab79d"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Export a csv with embeddings for fastapi\ndata = data[['name', 'topic', 'link', 'provider']]\ndata.to_csv('courses.csv', index=False)\nembeddings = pd.DataFrame(document_embeddings)\nembeddings.to_csv('embeddings.csv', index=False)","metadata":{"_uuid":"c71d32e2-0714-4827-8ce0-5241da0eb99b","_cell_guid":"1d152a10-a5f2-4f22-bed4-89003c49dbb7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T16:28:37.946995Z","iopub.execute_input":"2025-03-05T16:28:37.947311Z","iopub.status.idle":"2025-03-05T16:28:39.829861Z","shell.execute_reply.started":"2025-03-05T16:28:37.947286Z","shell.execute_reply":"2025-03-05T16:28:39.829072Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Use previous functions to process user input into vector and use cosine \n# Cosine Similarity to find the most related courses\n# removed document_embeddings, data, model, top_n=5 as it was unnecessary abstraction layer\n\n# our tool for our agent\ndef recommend_courses(user_input):\n    cleaned_input = clean_text(user_input)\n    input_embedding = model.encode([cleaned_input]) # Model must be initialized\n    similarities = cosine_similarity(input_embedding, document_embeddings)[0]\n    top_indices = np.argsort(similarities)[-5:][::-1]\n    recommendations = data.iloc[top_indices][['name', 'topic', 'link', 'provider']]\n    return recommendations\n\n\nuser_input = \"Python Data Analytics\"\nrecommendations = recommend_courses(user_input)\nrecommendations.head()","metadata":{"_uuid":"35733aa0-cfa5-4906-8acf-1cc3ce6e03d0","_cell_guid":"75e01ceb-702b-4b16-8229-f09e027434e9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T03:38:53.718419Z","iopub.execute_input":"2025-03-19T03:38:53.718855Z","iopub.status.idle":"2025-03-19T03:38:53.810599Z","shell.execute_reply.started":"2025-03-19T03:38:53.718814Z","shell.execute_reply":"2025-03-19T03:38:53.809724Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b55441a1465a419b8abf6ab9b1f8d50a"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                    name  \\\n65976  Marketing Analytics with Python: From Data to ...   \n61              Introduction to Data Science with Python   \n780                         Data Processing Using Python   \n309                                  Analytics in Python   \n138    Probability and Statistics in Data Science usi...   \n\n                                                   topic  \\\n65976                               Beginner to Advanced   \n61     Join Harvard University instructor Pavlos Prot...   \n780    Computer Programming, Python Programming, Comp...   \n309    Learn the fundamental of programming in Python...   \n138    Using Python, learn statistical and probabilis...   \n\n                                                    link  \\\n65976  https://www.udemy.com/course/python-for-market...   \n61     https://pll.harvard.edu/course/introduction-da...   \n780    https://www.coursera.org/learn/python-data-pro...   \n309       https://www.edx.org/course/analytics-in-python   \n138    https://www.edx.org/course/probability-and-sta...   \n\n                                            provider  \n65976                                          Udemy  \n61                                Harvard University  \n780                    Coursera - Nanjing University  \n309                        edX - Columbia University  \n138    edX - The University of California, San Diego  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n      <th>provider</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>65976</th>\n      <td>Marketing Analytics with Python: From Data to ...</td>\n      <td>Beginner to Advanced</td>\n      <td>https://www.udemy.com/course/python-for-market...</td>\n      <td>Udemy</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>Introduction to Data Science with Python</td>\n      <td>Join Harvard University instructor Pavlos Prot...</td>\n      <td>https://pll.harvard.edu/course/introduction-da...</td>\n      <td>Harvard University</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>Data Processing Using Python</td>\n      <td>Computer Programming, Python Programming, Comp...</td>\n      <td>https://www.coursera.org/learn/python-data-pro...</td>\n      <td>Coursera - Nanjing University</td>\n    </tr>\n    <tr>\n      <th>309</th>\n      <td>Analytics in Python</td>\n      <td>Learn the fundamental of programming in Python...</td>\n      <td>https://www.edx.org/course/analytics-in-python</td>\n      <td>edX - Columbia University</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>Probability and Statistics in Data Science usi...</td>\n      <td>Using Python, learn statistical and probabilis...</td>\n      <td>https://www.edx.org/course/probability-and-sta...</td>\n      <td>edX - The University of California, San Diego</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# API Testing with agentsa\n# key : AIzaSyAG29iZsYDXK_kTH3HcOcXloCKnlLdhiRc\n\nfrom google import genai\n\nclient = genai.Client(api_key=\"AIzaSyAG29iZsYDXK_kTH3HcOcXloCKnlLdhiRc\")\n\ndef ask_model(prompt):\n    response = client.models.generate_content(\n        model=\"gemma-3-27b-it\",\n        contents=prompt,\n    )\n    print(response.text)\n\n\n# Example usage\nuser_input = \"Chaucer and Middle English Literature\"\noptimized_query = ask_model(prompt=f\"Optimize this search query for search on our online courses BERT embeddings: {user_input}\")\n# recommendations = recommend_courses(optimized_query, document_embeddings, data, model_bert)\n# print(recommendations)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T03:27:36.348994Z","iopub.execute_input":"2025-03-19T03:27:36.349414Z","iopub.status.idle":"2025-03-19T03:28:02.168661Z","shell.execute_reply.started":"2025-03-19T03:27:36.349382Z","shell.execute_reply":"2025-03-19T03:28:02.167396Z"}},"outputs":[{"name":"stdout","text":"Okay, let's optimize the search query \"Chaucer and Middle English Literature\" for an online course database. Here's a breakdown of strategies, and several optimized queries, categorized by how sophisticated you want to get.  I'll also explain *why* each optimization is helpful.  I'll assume your database has fields like:\n\n* **Title:** Course Title\n* **Description:** Course Summary\n* **Keywords:**  Tags associated with the course\n* **Instructor:** Instructor Name\n* **Subject Area:** Broad category (e.g., Literature, History, etc.)\n\n**Understanding the Challenges & Goals**\n\n* **Broad Query:** \"Chaucer and Middle English Literature\" is fairly broad.  It will likely return *a lot* of results, many of which might be only tangentially related.\n* **Synonyms & Related Terms:** People might search for this topic using different phrasing.\n* **Specificity:**  Users might be looking for courses focusing *specifically* on Chaucer, or courses that *include* Chaucer as part of a larger Middle English survey.\n* **Boolean Logic:**  Leveraging \"AND\", \"OR\", and \"NOT\" can dramatically refine results.\n* **Phrase Searching:**  Using quotes (\"\") to search for exact phrases.\n* **Wildcards (if your database supports them):**  Can help catch variations in spelling or word endings.\n\n\n\n**Here are optimized queries, from simplest to most advanced, with explanations:**\n\n**1. Basic Refinement (Good Starting Point)**\n\n* **`\"Chaucer\" AND \"Middle English Literature\"`**\n\n   * **Why:**  This is a significant improvement.  The quotes force the search to look for those exact phrases.  The `AND` operator ensures that *both* phrases must be present in the course data (Title, Description, Keywords) for a result to be returned.  This narrows the results considerably.\n\n**2.  Adding Synonyms & Related Terms (Expanding Reach)**\n\n* **`(\"Chaucer\" OR \"Canterbury Tales\") AND (\"Middle English Literature\" OR \"Medieval English Literature\" OR \"Anglo-Saxon Literature\")`**\n\n   * **Why:**  This expands the search to include common related terms.  Someone interested in Chaucer might specifically search for \"Canterbury Tales.\"  \"Medieval English Literature\" and \"Anglo-Saxon Literature\" are often used interchangeably or in related contexts.  The `OR` operator means that *any* of the terms within the parentheses will satisfy that part of the query.  The overall `AND` still requires at least one term from each set of parentheses to be present.\n\n**3.  Field-Specific Search (Most Precise - Requires Database Knowledge)**\n\n* **`title:Chaucer OR title:\"Canterbury Tales\" OR description:(\"Middle English Literature\" OR \"Medieval English Literature\") OR keywords:(\"Chaucer\" OR \"Middle English\" OR \"Medieval\")`**\n\n   * **Why:** This is the most powerful if your database allows field-specific searching.  It tells the database *where* to look for the terms.\n     * `title:Chaucer` -  Search for \"Chaucer\" specifically in the course title.\n     * `description:(\"Middle English Literature\" OR \"Medieval English Literature\")` - Search for those phrases in the course description.\n     * `keywords:(\"Chaucer\" OR \"Middle English\" OR \"Medieval\")` - Search for those terms in the course keywords.\n   * **Important:**  The syntax (`title:`, `description:`, `keywords:`) will vary depending on your database's search language.  You might use different prefixes or symbols.\n\n**4.  Using Wildcards (If Supported - Be Careful!)**\n\n* **`\"Chaucer\" AND \"Middle English\" AND (literature OR literatur* OR medieval)`**\n\n   * **Why:**  The `literatur*` wildcard (the asterisk usually means \"any characters following\") will match \"literature\", \"literatures\", etc.  This can be helpful if your data entry is inconsistent.  *However*, be cautious with wildcards, as they can sometimes return irrelevant results.  Use them sparingly and test them thoroughly.\n\n**5.  Combining Field Specificity and Synonyms**\n\n* **`title:Chaucer OR title:\"Canterbury Tales\" OR (description:(\"Middle English Literature\" OR \"Medieval English Literature\") AND keywords:(\"Chaucer\" OR \"Middle English\"))`**\n\n   * **Why:** This combines the precision of field-specific searching with the broader reach of synonyms.  It prioritizes courses with \"Chaucer\" or \"Canterbury Tales\" in the title, but also finds courses that have \"Middle English Literature\" or \"Medieval English Literature\" in the description *and* relevant keywords.\n\n\n\n**Recommendations & Further Optimization**\n\n* **Database-Specific Syntax:**  *Crucially*, you need to know the exact search syntax supported by your online course database.  Consult its documentation.\n* **Testing:**  Test each query with a sample of your course data to see which one returns the most relevant results.\n* **User Feedback:**  Monitor search logs and user feedback to identify common search terms and refine your queries accordingly.  If users are consistently searching for something and not finding it, you need to adjust your search strategy.\n* **Faceted Navigation:**  Consider adding faceted navigation to your course database.  This allows users to filter results by subject area, level, instructor, etc., which can be more user-friendly than complex search queries.\n* **\"Did You Mean?\" Suggestions:** Implement a \"Did you mean?\" feature to suggest alternative search terms if the initial query returns few or no results.\n* **Keyword Standardization:**  Ensure that your course keywords are consistent and well-maintained.  This will improve the accuracy of keyword-based searches.\n\n\n\n\n**To help me refine these suggestions further, please tell me:**\n\n* **What database system are you using?** (e.g., Elasticsearch, Solr, MySQL, PostgreSQL, a custom system)\n* **What fields are available for searching?** (e.g., Title, Description, Keywords, Instructor)\n* **What is the search syntax supported by your database?** (e.g., how do you specify field-specific searches?)\n* **What is the approximate size of your course database?** (e.g., 100 courses, 1000 courses, 10,000+ courses)\n\n\n\nI hope this comprehensive response is helpful! Let me know if you have any other questions.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-b9aa0e4d70bc>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Chaucer and Middle English Literature\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0moptimized_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Optimize this search query for search on our online courses database: {user_input}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommend_courses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimized_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_bert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommendations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'recommend_courses' is not defined"],"ename":"NameError","evalue":"name 'recommend_courses' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"markdown","source":"* https://huggingface.co/docs/transformers/en/model_doc/bert","metadata":{"_uuid":"79ca17d0-35bb-44de-953f-ba1de3a529d6","_cell_guid":"16751f0b-0b52-4c3f-ac9f-d971f41b0b87","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}}]}