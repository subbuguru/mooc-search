{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3051937,"sourceType":"datasetVersion","datasetId":1868643},{"sourceId":7055553,"sourceType":"datasetVersion","datasetId":4057183},{"sourceId":9279572,"sourceType":"datasetVersion","datasetId":5456599}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T16:25:41.476288Z","iopub.execute_input":"2025-02-04T16:25:41.476606Z","iopub.status.idle":"2025-02-04T16:25:42.971402Z","shell.execute_reply.started":"2025-02-04T16:25:41.476577Z","shell.execute_reply":"2025-02-04T16:25:42.970151Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/edx-courses-dataset-2021/EdX.csv\n/kaggle/input/dataset-of-1200-coursera-courses/edx.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Barkeley_extension.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Oxford.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Stanford.csv\n/kaggle/input/dataset-of-1200-coursera-courses/udacity.csv\n/kaggle/input/dataset-of-1200-coursera-courses/alison.csv\n/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\n/kaggle/input/dataset-of-1200-coursera-courses/london school of economics.csv\n/kaggle/input/dataset-of-1200-coursera-courses/coursera_update.csv\n/kaggle/input/dataset-of-1200-coursera-courses/pluralsight.csv\n/kaggle/input/dataset-of-1200-coursera-courses/futurelearn.csv\n/kaggle/input/dataset-of-1200-coursera-courses/swayam.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\n/kaggle/input/multi-platform-online-courses-dataset/edx.csv\n/kaggle/input/multi-platform-online-courses-dataset/skillshare.csv\n/kaggle/input/multi-platform-online-courses-dataset/Udemy.csv\n/kaggle/input/multi-platform-online-courses-dataset/Coursera.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install NLTK\n!pip list | grep nltk\n! pip install -U kaleido\nimport nltk\n\nnltk.download('punkt')  \nnltk.download('wordnet')  \n\n# Unzip per this stackoverflow: https://stackoverflow.com/questions/73849624/getting-error-while-submitting-notebook-on-kaggle-even-after-importing-nltk-libr\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T17:09:44.786543Z","iopub.execute_input":"2025-02-04T17:09:44.786948Z","iopub.status.idle":"2025-02-04T17:11:23.125187Z","shell.execute_reply.started":"2025-02-04T17:09:44.786915Z","shell.execute_reply":"2025-02-04T17:11:23.123644Z"}},"outputs":[{"name":"stdout","text":"nltk                               3.2.4\nCollecting kaleido\n  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\nDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hInstalling collected packages: kaleido\nSuccessfully installed kaleido-0.2.1\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\nreplace /usr/share/nltk_data/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"# Setup\n\nimport pandas as pd\nimport numpy as np\nfrom gensim.models import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity \nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nimport re\n\n# Clean text \ndef clean_text(text):\n    lemma = WordNetLemmatizer() # lemmatizer\n    text = re.sub(\"[^A-Za-z1-9 ]\", \"\", text)\n    text = text.lower()\n    tokens = word_tokenize(text) # look into this tokenization\n    tokens = [lemma.lemmatize(word) for word in tokens # lemmatize words and remove stopwords \n                if word not in stopwords.words(\"english\")]\n    return tokens\n\n\n# Get the sentence embeddings for each course and user input with this function\n# First get the word embeddings and average them out for the sentence (aka course/input)\n# overall embedding\n\ndef get_document_embedding(doc, model):\n    embeddings = [model.wv[word] for word in doc if word in model.wv] # Get individual embeddings into a list\n    # Consider implementing exception handling \n    if len(embeddings) > 0:\n        return np.mean(embeddings, axis=0) \n    else:\n        return np.zeros(model.vector_size)\n\n# Use previous functions to process user input into vector and use cosine \n# Similarity to find the most related courses\ndef recommend_courses(user_input, document_embeddings, data, top_n=5):\n    cleaned_input = clean_text(user_input)\n    input_embedding = get_document_embedding(cleaned_input, word2vec_model)\n    similarities = cosine_similarity([input_embedding], document_embeddings)[0]\n    top_indices = np.argsort(similarities)[-top_n:][::-1]\n    recommendations = data.iloc[top_indices][['name', 'topic', 'link']]\n    return recommendations\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T17:13:08.728072Z","iopub.execute_input":"2025-02-04T17:13:08.728515Z","iopub.status.idle":"2025-02-04T17:13:08.738002Z","shell.execute_reply.started":"2025-02-04T17:13:08.728483Z","shell.execute_reply":"2025-02-04T17:13:08.736285Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"# Experiment with other data\n# edx, coursera, harvard, mit ocw\n# https://sparkbyexamples.com/pandas/pandas-read-multiple-csv-files/#:~:text=Load%20each%20file%20into%20individual,each%20file%20individually%20if%20needed.\n\n# Normalize/clean course data to the name, topic, link, text format for now\n\ndataMit = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\")\ndataMit.columns = map(str.lower, dataMit.columns)\ndataMit.rename(columns={'name ': 'name'}, inplace=True)\ndataMit = dataMit.drop(columns=['sub category', 'category', 'resource type', 'course code', 'instructure'])\ndataMit.rename(columns={'course link': 'link'}, inplace=True)\ndataMit['text'] = dataMit['name'] + \" \" + dataMit['topic'] \ndataMit = dataMit[['name', 'topic', 'link', 'text']]\n\n\n\ndataHarvard = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\")\ndataHarvard.columns = map(str.lower, dataHarvard.columns)\ndataHarvard.rename(columns={'link to course': 'link', 'about': 'topic'}, inplace=True)\n# Remove rows where the price is not 'Free' (gpt code)\ndataHarvard = dataHarvard[dataHarvard['price'] == 'Free']\n# Select only the columns 'name', 'topic', and 'link'\ndataHarvard = dataHarvard[['name', 'topic', 'link']]\ndataHarvard['text'] = dataHarvard['name'] + \" \" + dataHarvard['topic'] \nprint(dataHarvard.head())\n\n# Coursera data\n\n# Read in 2021 EdXdata\ndataEdx = pd.read_csv(\"/kaggle/input/edx-courses-dataset-2021/EdX.csv\")\ndataEdx.columns = map(str.lower, dataEdx.columns)\ndataEdx[\"topic\"] = dataEdx['about'] + '. ' + dataEdx['course description']\ndataEdx = dataEdx[['name', 'topic', 'link']]\ndataEdx['text'] = dataEdx['name'] + \" \" + dataEdx[\"topic\"]\n# dataEdx.head()\n\n# Read in ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T17:13:32.058852Z","iopub.execute_input":"2025-02-04T17:13:32.059237Z","iopub.status.idle":"2025-02-04T17:13:32.128428Z","shell.execute_reply.started":"2025-02-04T17:13:32.059195Z","shell.execute_reply":"2025-02-04T17:13:32.127255Z"}},"outputs":[{"name":"stdout","text":"                                                 name  \\\n0                 PredictionX: Lost Without Longitude   \n1   Nonprofit Financial Stewardship Webinar: Intro...   \n2              CS50: Introduction to Computer Science   \n10           PredictionX: Omens, Oracles & Prophecies   \n11             Systematic Approaches to Policy Design   \n\n                                                topic  \\\n0   Explore the history of navigation, from stars ...   \n1   The Introduction to Nonprofit Accounting and F...   \n2   An introduction to the intellectual enterprise...   \n10  An overview of divination systems, ranging fro...   \n11  This free online course from Harvard Kennedy S...   \n\n                                                 link  \\\n0   https://pll.harvard.edu/course/predictionx-los...   \n1   https://pll.harvard.edu/course/nonprofit-finan...   \n2   https://pll.harvard.edu/course/cs50-introducti...   \n10  https://pll.harvard.edu/course/predictionx-ome...   \n11  https://pll.harvard.edu/course/systematic-appr...   \n\n                                                 text  \n0   PredictionX: Lost Without Longitude Explore th...  \n1   Nonprofit Financial Stewardship Webinar: Intro...  \n2   CS50: Introduction to Computer Science An intr...  \n10  PredictionX: Omens, Oracles & Prophecies An ov...  \n11  Systematic Approaches to Policy Design This fr...  \n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"# Create a Combined Dataframe\ndata = pd.concat([dataHarvard, dataMit, dataEdx])\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T17:14:07.173850Z","iopub.execute_input":"2025-02-04T17:14:07.174316Z","iopub.status.idle":"2025-02-04T17:14:07.187886Z","shell.execute_reply.started":"2025-02-04T17:14:07.174278Z","shell.execute_reply":"2025-02-04T17:14:07.186656Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"                                                 name  \\\n0                 PredictionX: Lost Without Longitude   \n1   Nonprofit Financial Stewardship Webinar: Intro...   \n2              CS50: Introduction to Computer Science   \n10           PredictionX: Omens, Oracles & Prophecies   \n11             Systematic Approaches to Policy Design   \n\n                                                topic  \\\n0   Explore the history of navigation, from stars ...   \n1   The Introduction to Nonprofit Accounting and F...   \n2   An introduction to the intellectual enterprise...   \n10  An overview of divination systems, ranging fro...   \n11  This free online course from Harvard Kennedy S...   \n\n                                                 link  \\\n0   https://pll.harvard.edu/course/predictionx-los...   \n1   https://pll.harvard.edu/course/nonprofit-finan...   \n2   https://pll.harvard.edu/course/cs50-introducti...   \n10  https://pll.harvard.edu/course/predictionx-ome...   \n11  https://pll.harvard.edu/course/systematic-appr...   \n\n                                                 text  \n0   PredictionX: Lost Without Longitude Explore th...  \n1   Nonprofit Financial Stewardship Webinar: Intro...  \n2   CS50: Introduction to Computer Science An intr...  \n10  PredictionX: Omens, Oracles & Prophecies An ov...  \n11  Systematic Approaches to Policy Design This fr...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PredictionX: Lost Without Longitude</td>\n      <td>Explore the history of navigation, from stars ...</td>\n      <td>https://pll.harvard.edu/course/predictionx-los...</td>\n      <td>PredictionX: Lost Without Longitude Explore th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nonprofit Financial Stewardship Webinar: Intro...</td>\n      <td>The Introduction to Nonprofit Accounting and F...</td>\n      <td>https://pll.harvard.edu/course/nonprofit-finan...</td>\n      <td>Nonprofit Financial Stewardship Webinar: Intro...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CS50: Introduction to Computer Science</td>\n      <td>An introduction to the intellectual enterprise...</td>\n      <td>https://pll.harvard.edu/course/cs50-introducti...</td>\n      <td>CS50: Introduction to Computer Science An intr...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>PredictionX: Omens, Oracles &amp; Prophecies</td>\n      <td>An overview of divination systems, ranging fro...</td>\n      <td>https://pll.harvard.edu/course/predictionx-ome...</td>\n      <td>PredictionX: Omens, Oracles &amp; Prophecies An ov...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Systematic Approaches to Policy Design</td>\n      <td>This free online course from Harvard Kennedy S...</td>\n      <td>https://pll.harvard.edu/course/systematic-appr...</td>\n      <td>Systematic Approaches to Policy Design This fr...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"# The list of tokenized sentences, ie our Corpus \ndata['cleaned_text'] = data['text'].apply(clean_text) # Add clean text column to dataframe\ndata['cleaned_text'].head()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T17:14:12.170949Z","iopub.execute_input":"2025-02-04T17:14:12.171371Z","iopub.status.idle":"2025-02-04T17:14:33.665475Z","shell.execute_reply.started":"2025-02-04T17:14:12.171336Z","shell.execute_reply":"2025-02-04T17:14:33.664383Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"0     [predictionx, lost, without, longitude, explor...\n1     [nonprofit, financial, stewardship, webinar, i...\n2     [cs5, introduction, computer, science, introdu...\n10    [predictionx, omen, oracle, prophecy, overview...\n11    [systematic, approach, policy, design, free, o...\nName: cleaned_text, dtype: object"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"# Corpus = list of tokenized sentences (already cleaned)\ncorpus = data['cleaned_text'].tolist()\ncorpus[0]\n\n# Train Word2Vec\nmodel = Word2Vec(\n    sentences=corpus,\n    vector_size=100,\n    window=5,       # Larger window for broader context\n    min_count=5,    # Ignore rare words\n    workers=4       # Parallelize training\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T17:14:56.092568Z","iopub.execute_input":"2025-02-04T17:14:56.092997Z"}},"outputs":[{"name":"stdout","text":"words in corpus: 100809\ncorpus count: 3382\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# DATA exploration\n\nvocab_len = len(model.wv)\nprint(f'Vocabulary size: {vocab_len}')\n\nprint('First 10 words in vocabulary:')\nkey_vocab = model.wv.index_to_key[:10]\nprint(key_vocab)\n\nword1 = 'programming'; word2 = 'python'\nsimilarity = model.wv.similarity(word1,word2)\nprint(f'\\nsimilarity b/w {word1} and {word2} {round(similarity,2)}\\n')\n\n# View similar words based on gensim's model\nprint('Similar Words')\nsimilar_words = {search_term: [item[0] for item in model.wv.most_similar([search_term], topn=5)]\n                  for search_term in key_vocab}\nsimilar_words\n\n# Lower dimensionality visualisation of embeddings (100->2)\nimport plotly.express as px\nfrom sklearn.manifold import TSNE\nimport warnings; warnings.filterwarnings('ignore')\n\nwords = sum([[k] + v for k, v in similar_words.items()], [])\nwvs = model.wv[words]\n\ntsne = TSNE(n_components=2, \n            random_state=0, \n            n_iter=10000)\n\nX = tsne.fit_transform(wvs)\nlabels = words\n    \nfig = px.scatter(X[:, 0], X[:, 1],text=labels,\n           template='plotly_white',\n           width=800,\n           title='Word Embedding Visualisation')\nfig.show('svg',dpi=300)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T17:11:23.646084Z","iopub.status.idle":"2025-02-04T17:11:23.646470Z","shell.execute_reply":"2025-02-04T17:11:23.646328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get a list of the document embedding vector for each sentence in the cleaned text data. The indices will be aligned with the original course rows in dataframe\ndocument_embeddings = [get_document_embedding(doc, model)\n                      for doc in data['cleaned_text']]\nprint(f'list of sentence vectors/sentences: {len(document_embeddings)}')\nprint(f'each sentence has {document_embeddings[0].shape} dimensions')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T17:11:26.800539Z","iopub.execute_input":"2025-02-04T17:11:26.800966Z","iopub.status.idle":"2025-02-04T17:11:27.145860Z","shell.execute_reply.started":"2025-02-04T17:11:26.800933Z","shell.execute_reply":"2025-02-04T17:11:27.144682Z"}},"outputs":[{"name":"stdout","text":"list of sentence vectors/sentences: 3382\neach sentence has (100,) dimensions\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"# User interface (abstracted away)\nuser_input = \"Single Variable Calculus\"\nrecommendations = recommend_courses(user_input, document_embeddings, data)\nrecommendations.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T17:11:51.388480Z","iopub.execute_input":"2025-02-04T17:11:51.388900Z","iopub.status.idle":"2025-02-04T17:11:51.414649Z","shell.execute_reply.started":"2025-02-04T17:11:51.388864Z","shell.execute_reply":"2025-02-04T17:11:51.413305Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"                                                   name  \\\n1711        History of Women in Science and Engineering   \n881                        Operating System Engineering   \n81    Introduction to Numerical Analysis for Enginee...   \n50    Introduction to Numerical Analysis for Enginee...   \n537               Mathematical Methods in Nanophotonics   \n\n                                                  topic  \\\n1711                   Engineering, Science, Humanities   \n881   Engineering, Computer Science, Software Design...   \n81           Engineering, Computer Science, Mathematics   \n50           Engineering, Computer Science, Mathematics   \n537                       Engineering, Science, Physics   \n\n                                                   link  \n1711  https://ocw.mit.edu/courses/wgs-s10-history-of...  \n881   https://ocw.mit.edu/courses/6-828-operating-sy...  \n81    https://ocw.mit.edu/courses/2-993j-introductio...  \n50    https://ocw.mit.edu/courses/2-993j-introductio...  \n537   https://ocw.mit.edu/courses/18-369-mathematica...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1711</th>\n      <td>History of Women in Science and Engineering</td>\n      <td>Engineering, Science, Humanities</td>\n      <td>https://ocw.mit.edu/courses/wgs-s10-history-of...</td>\n    </tr>\n    <tr>\n      <th>881</th>\n      <td>Operating System Engineering</td>\n      <td>Engineering, Computer Science, Software Design...</td>\n      <td>https://ocw.mit.edu/courses/6-828-operating-sy...</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>Introduction to Numerical Analysis for Enginee...</td>\n      <td>Engineering, Computer Science, Mathematics</td>\n      <td>https://ocw.mit.edu/courses/2-993j-introductio...</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>Introduction to Numerical Analysis for Enginee...</td>\n      <td>Engineering, Computer Science, Mathematics</td>\n      <td>https://ocw.mit.edu/courses/2-993j-introductio...</td>\n    </tr>\n    <tr>\n      <th>537</th>\n      <td>Mathematical Methods in Nanophotonics</td>\n      <td>Engineering, Science, Physics</td>\n      <td>https://ocw.mit.edu/courses/18-369-mathematica...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":57},{"cell_type":"markdown","source":"# Important Notes\n\n* Original Source: https://www.kaggle.com/code/shtrausslearning/nlp-edx-course-recommendations\n* DeepSeek AI for original base which also calls the document embeddings for the input\n* I have added comments to better study and understand the code as a base to build off of\n* Instead of directly matching to a course index in the dataset which limits the use of the model\n\n# Todo (to better understand and be able to present on this topic)\n\n* Study cosine similarity\\\n* Word2Vec and stopwords/lemmatization","metadata":{}}]}