{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3051937,"sourceType":"datasetVersion","datasetId":1868643},{"sourceId":5103339,"sourceType":"datasetVersion","datasetId":2423448},{"sourceId":9279572,"sourceType":"datasetVersion","datasetId":5456599},{"sourceId":9976645,"sourceType":"datasetVersion","datasetId":6138541}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T22:20:32.790361Z","iopub.execute_input":"2025-02-04T22:20:32.790605Z","iopub.status.idle":"2025-02-04T22:20:34.075172Z","shell.execute_reply.started":"2025-02-04T22:20:32.790582Z","shell.execute_reply":"2025-02-04T22:20:34.074070Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/multi-platform-online-courses-dataset/edx.csv\n/kaggle/input/multi-platform-online-courses-dataset/skillshare.csv\n/kaggle/input/multi-platform-online-courses-dataset/Udemy.csv\n/kaggle/input/multi-platform-online-courses-dataset/Coursera.csv\n/kaggle/input/edx-courses-dataset-2021/EdX.csv\n/kaggle/input/dataset-of-1200-coursera-courses/edx.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Barkeley_extension.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Oxford.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Stanford.csv\n/kaggle/input/dataset-of-1200-coursera-courses/udacity.csv\n/kaggle/input/dataset-of-1200-coursera-courses/alison.csv\n/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\n/kaggle/input/dataset-of-1200-coursera-courses/london school of economics.csv\n/kaggle/input/dataset-of-1200-coursera-courses/coursera_update.csv\n/kaggle/input/dataset-of-1200-coursera-courses/pluralsight.csv\n/kaggle/input/dataset-of-1200-coursera-courses/futurelearn.csv\n/kaggle/input/dataset-of-1200-coursera-courses/swayam.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install NLTK\n!pip list | grep nltk\n! pip install -U kaleido\nimport nltk\n\nnltk.download('punkt')  \nnltk.download('wordnet')  \n\n# Unzip per this stackoverflow: https://stackoverflow.com/questions/73849624/getting-error-while-submitting-notebook-on-kaggle-even-after-importing-nltk-libr\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T17:03:13.727168Z","iopub.execute_input":"2025-02-05T17:03:13.727508Z","iopub.status.idle":"2025-02-05T17:03:25.866259Z","shell.execute_reply.started":"2025-02-05T17:03:13.727482Z","shell.execute_reply":"2025-02-05T17:03:25.865228Z"}},"outputs":[{"name":"stdout","text":"nltk                               3.2.4\nCollecting kaleido\n  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\nDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: kaleido\nSuccessfully installed kaleido-0.2.1\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Setup\n\nimport pandas as pd\nimport numpy as np\nfrom gensim.models import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity \nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nimport re\n\n# Clean text \ndef clean_text(text):\n    lemma = WordNetLemmatizer() # lemmatizer\n    text = re.sub(\"[^A-Za-z0-9 ]\", \"\", text)\n    text = text.lower()\n    tokens = word_tokenize(text) # look into this tokenization\n    tokens = [lemma.lemmatize(word) for word in tokens # lemmatize words and remove stopwords \n                if word not in stopwords.words(\"english\")]\n    return tokens\n\n\n# Get the sentence embeddings for each course and user input with this function\n# First get the word embeddings and average them out for the sentence (aka course/input)\n# overall embedding\n\ndef get_document_embedding(doc, model):\n    embeddings = [model.wv[word] for word in doc if word in model.wv] # Get individual embeddings into a list\n    # Consider implementing exception handling \n    if len(embeddings) > 0:\n        return np.mean(embeddings, axis=0) \n    else:\n        return np.zeros(model.vector_size)\n\n# Use previous functions to process user input into vector and use cosine \n# Similarity to find the most related courses\ndef recommend_courses(user_input, document_embeddings, data, top_n=5):\n    cleaned_input = clean_text(user_input)\n    input_embedding = get_document_embedding(cleaned_input, model)\n    similarities = cosine_similarity([input_embedding], document_embeddings)[0]\n    top_indices = np.argsort(similarities)[-top_n:][::-1]\n    recommendations = data.iloc[top_indices][['name', 'topic', 'link', 'provider']]\n    return recommendations\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T17:03:34.413642Z","iopub.execute_input":"2025-02-05T17:03:34.414434Z","iopub.status.idle":"2025-02-05T17:03:53.385076Z","shell.execute_reply.started":"2025-02-05T17:03:34.414394Z","shell.execute_reply":"2025-02-05T17:03:53.384000Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Experiment with other data\n# edx, coursera, harvard, mit ocw\n# https://sparkbyexamples.com/pandas/pandas-read-multiple-csv-files/#:~:text=Load%20each%20file%20into%20individual,each%20file%20individually%20if%20needed.\n\n# Normalize/clean course data to the name, topic, link, text format for now\n\ndataMit = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\")\n# print(dataMit.head())\ndataMit.columns = map(str.lower, dataMit.columns)\ndataMit.rename(columns={'name ': 'name'}, inplace=True)\ndataMit.rename(columns={'course link': 'link'}, inplace=True)\ndataMit['text'] = dataMit['name'] + \" \" + dataMit['topic'] \ndataMit['provider'] = 'Massachussets Institute of Technology'\ndataMit = dataMit[['name', 'topic', 'link', 'provider', 'text']]\n\n\ndataHarvard = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\")\n# print(dataHarvard.head())\ndataHarvard.columns = map(str.lower, dataHarvard.columns)\ndataHarvard.rename(columns={'link to course': 'link', 'about': 'topic'}, inplace=True)\ndataHarvard = dataHarvard[dataHarvard['price'] == 'Free']\ndataHarvard['text'] = dataHarvard['name'] + \" \" + dataHarvard['topic'] \ndataHarvard['provider'] = 'Harvard University'\ndataHarvard = dataHarvard[['name', 'topic', 'link', 'provider', 'text']]\n\n\ndataEdx = pd.read_csv(\"/kaggle/input/edx-courses-dataset-2021/EdX.csv\")\n# print(dataEdx.head())\ndataEdx.columns = map(str.lower, dataEdx.columns)\ndataEdx[\"topic\"] = dataEdx['about'] + '. ' + dataEdx['course description']\ndataEdx[\"provider\"] = 'edX - ' + dataEdx['university']\ndataEdx['text'] = dataEdx['name'] + \" \" + dataEdx[\"topic\"]\ndataEdx = dataEdx[['name', 'topic', 'link', 'provider', 'text']]\n\n\n# Udemy\ndataUdemy = pd.read_csv(\"/kaggle/input/udemy-course-dataset-categories-ratings-and-trends/udemy_courses.csv\")\ndataUdemy.columns = map(str.lower, dataUdemy.columns)\ndataUdemy.rename(columns={\n    'title': 'name',\n    'headline': 'topic',\n    'url': 'link',\n}, inplace=True)\n# only keep free courses\ndataUdemy = dataUdemy[dataUdemy['is_paid'] == False]\n# Since Udemy courses are user generated, filter only courses with rating over 4.5\ndataUdemy['provider'] = 'Udemy'\ndataUdemy = dataUdemy[dataUdemy['rating'] > 4.5 ]\ndataUdemy['text'] = dataUdemy['name'] + \" \" + dataUdemy['topic']\ndataUdemy = dataUdemy[['name', 'topic', 'link', 'provider', 'text']]\nprint(dataUdemy.head())\n\n\n# Coursera\ndataCoursera = pd.read_csv(\"/kaggle/input/coursera-free-courses-dataset/coursera.csv\")\ndataCoursera.rename(columns={\n    'title': 'name',\n    'skills': 'topic',\n    'url': 'link',\n}, inplace=True)\ndataCoursera = dataCoursera[dataCoursera['price'] == 'Free']\ndataCoursera['text'] = dataCoursera['name'] + \" \" + np.where(pd.notna(dataCoursera['topic']), dataCoursera['topic'], \"\")\n\ndataCoursera['provider'] = 'Coursera - ' + dataCoursera['course_by']\ndataCoursera = dataCoursera[['name', 'topic', 'link', 'provider', 'text']]\ndataCoursera = dataCoursera.fillna(\"\") # Fill null values\n\n# print(dataCoursera.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T17:16:53.015292Z","iopub.execute_input":"2025-02-05T17:16:53.015645Z","iopub.status.idle":"2025-02-05T17:16:56.006122Z","shell.execute_reply.started":"2025-02-05T17:16:53.015619Z","shell.execute_reply":"2025-02-05T17:16:56.005171Z"}},"outputs":[{"name":"stdout","text":"                                                    name  \\\n26443                           Stock Market Foundations   \n26445  The Complete Course On Understanding Blockchai...   \n26446  Bitcoin or How I Learned to Stop Worrying and ...   \n26448  Blockchain cryptocurrency course 101 for absol...   \n26449  Trading Options For Consistent Returns: Option...   \n\n                                                   topic  \\\n26443  The Market isn't a Mystery, It’s a Playground....   \n26445  A Beginner's Guide to Authentic Knowledge on B...   \n26446  The definitive guide to understand what the bi...   \n26448  A complete guide to anyone who wants to really...   \n26449                     The Foundation For Consistency   \n\n                                                    link provider  \\\n26443  https://www.udemy.com/course/how-to-invest-in-...    Udemy   \n26445  https://www.udemy.com/course/understanding-blo...    Udemy   \n26446  https://www.udemy.com/course/bitcoin-or-how-i-...    Udemy   \n26448  https://www.udemy.com/course/blockchain-crypto...    Udemy   \n26449  https://www.udemy.com/course/trading-options-f...    Udemy   \n\n                                                    text  \n26443  Stock Market Foundations The Market isn't a My...  \n26445  The Complete Course On Understanding Blockchai...  \n26446  Bitcoin or How I Learned to Stop Worrying and ...  \n26448  Blockchain cryptocurrency course 101 for absol...  \n26449  Trading Options For Consistent Returns: Option...  \n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Create a Combined Dataframe\ndata = pd.concat([dataUdemy, dataMit, dataHarvard, dataEdx, dataCoursera])\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T17:17:02.647592Z","iopub.execute_input":"2025-02-05T17:17:02.647962Z","iopub.status.idle":"2025-02-05T17:17:02.660492Z","shell.execute_reply.started":"2025-02-05T17:17:02.647927Z","shell.execute_reply":"2025-02-05T17:17:02.659577Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                                    name  \\\n26443                           Stock Market Foundations   \n26445  The Complete Course On Understanding Blockchai...   \n26446  Bitcoin or How I Learned to Stop Worrying and ...   \n26448  Blockchain cryptocurrency course 101 for absol...   \n26449  Trading Options For Consistent Returns: Option...   \n\n                                                   topic  \\\n26443  The Market isn't a Mystery, It’s a Playground....   \n26445  A Beginner's Guide to Authentic Knowledge on B...   \n26446  The definitive guide to understand what the bi...   \n26448  A complete guide to anyone who wants to really...   \n26449                     The Foundation For Consistency   \n\n                                                    link provider  \\\n26443  https://www.udemy.com/course/how-to-invest-in-...    Udemy   \n26445  https://www.udemy.com/course/understanding-blo...    Udemy   \n26446  https://www.udemy.com/course/bitcoin-or-how-i-...    Udemy   \n26448  https://www.udemy.com/course/blockchain-crypto...    Udemy   \n26449  https://www.udemy.com/course/trading-options-f...    Udemy   \n\n                                                    text  \n26443  Stock Market Foundations The Market isn't a My...  \n26445  The Complete Course On Understanding Blockchai...  \n26446  Bitcoin or How I Learned to Stop Worrying and ...  \n26448  Blockchain cryptocurrency course 101 for absol...  \n26449  Trading Options For Consistent Returns: Option...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n      <th>provider</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26443</th>\n      <td>Stock Market Foundations</td>\n      <td>The Market isn't a Mystery, It’s a Playground....</td>\n      <td>https://www.udemy.com/course/how-to-invest-in-...</td>\n      <td>Udemy</td>\n      <td>Stock Market Foundations The Market isn't a My...</td>\n    </tr>\n    <tr>\n      <th>26445</th>\n      <td>The Complete Course On Understanding Blockchai...</td>\n      <td>A Beginner's Guide to Authentic Knowledge on B...</td>\n      <td>https://www.udemy.com/course/understanding-blo...</td>\n      <td>Udemy</td>\n      <td>The Complete Course On Understanding Blockchai...</td>\n    </tr>\n    <tr>\n      <th>26446</th>\n      <td>Bitcoin or How I Learned to Stop Worrying and ...</td>\n      <td>The definitive guide to understand what the bi...</td>\n      <td>https://www.udemy.com/course/bitcoin-or-how-i-...</td>\n      <td>Udemy</td>\n      <td>Bitcoin or How I Learned to Stop Worrying and ...</td>\n    </tr>\n    <tr>\n      <th>26448</th>\n      <td>Blockchain cryptocurrency course 101 for absol...</td>\n      <td>A complete guide to anyone who wants to really...</td>\n      <td>https://www.udemy.com/course/blockchain-crypto...</td>\n      <td>Udemy</td>\n      <td>Blockchain cryptocurrency course 101 for absol...</td>\n    </tr>\n    <tr>\n      <th>26449</th>\n      <td>Trading Options For Consistent Returns: Option...</td>\n      <td>The Foundation For Consistency</td>\n      <td>https://www.udemy.com/course/trading-options-f...</td>\n      <td>Udemy</td>\n      <td>Trading Options For Consistent Returns: Option...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# The list of tokenized sentences, ie our Corpus \ndata['cleaned_text'] = data['text'].apply(clean_text) # Add clean text column to dataframe\ndata['cleaned_text'].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:38:06.096745Z","iopub.execute_input":"2025-02-04T23:38:06.097141Z","iopub.status.idle":"2025-02-04T23:38:31.484884Z","shell.execute_reply.started":"2025-02-04T23:38:06.097068Z","shell.execute_reply":"2025-02-04T23:38:31.483712Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"0    [energy, economics, science, economics, social...\n1    [identity, difference, social, science, societ...\n2    [single, variable, calculus, mathematics, diff...\n3    [libertarianism, history, humanity, history, s...\n4    [introductory, biology, science, health, medic...\nName: cleaned_text, dtype: object"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"# Corpus = list of tokenized sentences (already cleaned)\ncorpus = data['cleaned_text'].tolist()\nprint(corpus[0])\n\n# Train Word2Vec\nmodel = Word2Vec(\n    sentences=corpus,\n    vector_size=40,\n    window=5,       # Larger window for broader context\n    min_count=5,    # Ignore very rare words\n    workers=4,\n    epochs=10\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:38:36.024852Z","iopub.execute_input":"2025-02-04T23:38:36.025321Z","iopub.status.idle":"2025-02-04T23:38:36.991002Z","shell.execute_reply.started":"2025-02-04T23:38:36.025287Z","shell.execute_reply":"2025-02-04T23:38:36.989806Z"}},"outputs":[{"name":"stdout","text":"['energy', 'economics', 'science', 'economics', 'social', 'science']\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"# Get a list of the document embedding vector for each sentence in the cleaned text data. The indices will be aligned with the original course rows in dataframe\ndocument_embeddings = [get_document_embedding(doc, model)\n                      for doc in data['cleaned_text']]\nprint(f'list of sentence vectors/sentences: {len(document_embeddings)}')\nprint(f'each sentence has {document_embeddings[0].shape} dimensions')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:38:42.164908Z","iopub.execute_input":"2025-02-04T23:38:42.165352Z","iopub.status.idle":"2025-02-04T23:38:42.512126Z","shell.execute_reply.started":"2025-02-04T23:38:42.165318Z","shell.execute_reply":"2025-02-04T23:38:42.510997Z"}},"outputs":[{"name":"stdout","text":"list of sentence vectors/sentences: 4338\neach sentence has (40,) dimensions\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"# User interface (abstracted away)\nuser_input = \"data and python\"\nrecommendations = recommend_courses(user_input, document_embeddings, data)\nrecommendations.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T23:38:59.547789Z","iopub.execute_input":"2025-02-04T23:38:59.548279Z","iopub.status.idle":"2025-02-04T23:38:59.570180Z","shell.execute_reply.started":"2025-02-04T23:38:59.548240Z","shell.execute_reply":"2025-02-04T23:38:59.569191Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"                                               name  \\\n590        用Python玩转数据 Data Processing Using Python   \n113                          Data Science: R Basics   \n71                                 Statistics and R   \n596  Базы данных и SQL в обработке и анализе данных   \n174                          Python Data Structures   \n\n                                                 topic  \\\n590  Computer Programming, Python Programming, Stat...   \n113  Build a foundation in R and learn how to wrang...   \n71   An introduction to basic statistical concepts ...   \n596  Data Management, Databases, SQL, Statistical P...   \n174  The second course in Python for Everybody expl...   \n\n                                                  link  \\\n590            https://www.coursera.org/learn/hipython   \n113  https://pll.harvard.edu/course/data-science-r-...   \n71     https://pll.harvard.edu/course/statistics-and-r   \n596  https://www.coursera.org/learn/sql-data-scienc...   \n174  https://www.edx.org/course/python-data-structures   \n\n                             provider  \n590     Coursera - Nanjing University  \n113                Harvard University  \n71                 Harvard University  \n596     Coursera - IBM Skills Network  \n174  edX - The University of Michigan  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n      <th>provider</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>590</th>\n      <td>用Python玩转数据 Data Processing Using Python</td>\n      <td>Computer Programming, Python Programming, Stat...</td>\n      <td>https://www.coursera.org/learn/hipython</td>\n      <td>Coursera - Nanjing University</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>Data Science: R Basics</td>\n      <td>Build a foundation in R and learn how to wrang...</td>\n      <td>https://pll.harvard.edu/course/data-science-r-...</td>\n      <td>Harvard University</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>Statistics and R</td>\n      <td>An introduction to basic statistical concepts ...</td>\n      <td>https://pll.harvard.edu/course/statistics-and-r</td>\n      <td>Harvard University</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>Базы данных и SQL в обработке и анализе данных</td>\n      <td>Data Management, Databases, SQL, Statistical P...</td>\n      <td>https://www.coursera.org/learn/sql-data-scienc...</td>\n      <td>Coursera - IBM Skills Network</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>Python Data Structures</td>\n      <td>The second course in Python for Everybody expl...</td>\n      <td>https://www.edx.org/course/python-data-structures</td>\n      <td>edX - The University of Michigan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":65},{"cell_type":"markdown","source":"# Important Notes\n\n* Original Source: https://www.kaggle.com/code/shtrausslearning/nlp-edx-course-recommendations\n* DeepSeek AI for original base which also calls the document embeddings for the input\n* I have added comments to better study and understand the code as a base to build off of\n* Instead of directly matching to a course index in the dataset which limits the use of the model\n\n# Todo (to better understand and be able to present on this topic)\n\n* Study cosine similarity\\\n* Word2Vec and stopwords/lemmatization\n* Coursera, futurelearn, udemy\n* Build a frontend for the app\n\n# Improvements\n\nreshaped corpus as list instead of series, increased context window, ","metadata":{}}]}