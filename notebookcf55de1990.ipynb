{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3051937,"sourceType":"datasetVersion","datasetId":1868643},{"sourceId":5103339,"sourceType":"datasetVersion","datasetId":2423448},{"sourceId":9279572,"sourceType":"datasetVersion","datasetId":5456599},{"sourceId":9976645,"sourceType":"datasetVersion","datasetId":6138541}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-06T19:07:07.919767Z","iopub.execute_input":"2025-02-06T19:07:07.920189Z","iopub.status.idle":"2025-02-06T19:07:09.586065Z","shell.execute_reply.started":"2025-02-06T19:07:07.920149Z","shell.execute_reply":"2025-02-06T19:07:09.584798Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/udemy-course-dataset-categories-ratings-and-trends/udemy_courses.csv\n/kaggle/input/coursera-free-courses-dataset/coursera.csv\n/kaggle/input/dataset-of-1200-coursera-courses/edx.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Barkeley_extension.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Oxford.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Stanford.csv\n/kaggle/input/dataset-of-1200-coursera-courses/udacity.csv\n/kaggle/input/dataset-of-1200-coursera-courses/alison.csv\n/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\n/kaggle/input/dataset-of-1200-coursera-courses/london school of economics.csv\n/kaggle/input/dataset-of-1200-coursera-courses/coursera_update.csv\n/kaggle/input/dataset-of-1200-coursera-courses/pluralsight.csv\n/kaggle/input/dataset-of-1200-coursera-courses/futurelearn.csv\n/kaggle/input/dataset-of-1200-coursera-courses/swayam.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\n/kaggle/input/edx-courses-dataset-2021/EdX.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install NLTK\n!pip list | grep nltk\n! pip install -U kaleido\nimport nltk\n\nnltk.download('punkt')  \nnltk.download('wordnet')  \n\n# Unzip per this stackoverflow: https://stackoverflow.com/questions/73849624/getting-error-while-submitting-notebook-on-kaggle-even-after-importing-nltk-libr\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T19:07:13.985921Z","iopub.execute_input":"2025-02-06T19:07:13.986435Z","iopub.status.idle":"2025-02-06T19:07:28.130252Z","shell.execute_reply.started":"2025-02-06T19:07:13.986382Z","shell.execute_reply":"2025-02-06T19:07:28.128771Z"}},"outputs":[{"name":"stdout","text":"nltk                               3.2.4\nCollecting kaleido\n  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\nDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: kaleido\nSuccessfully installed kaleido-0.2.1\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Setup\n\nimport pandas as pd\nimport numpy as np\nfrom gensim.models import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity \nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nimport re\n\n# Clean text \ndef clean_text(text):\n    lemma = WordNetLemmatizer() # lemmatizer\n    text = re.sub(\"[^A-Za-z0-9 ]\", \"\", text)\n    text = text.lower()\n    tokens = word_tokenize(text) # look into this tokenization\n    tokens = [lemma.lemmatize(word) for word in tokens # lemmatize words and remove stopwords \n                if word not in stopwords.words(\"english\")]\n    return tokens\n\n\n# Get the sentence embeddings for each course and user input with this function\n# First get the word embeddings and average them out for the sentence (aka course/input)\n# overall embedding\n\ndef get_document_embedding(doc, model):\n    embeddings = [model.wv[word] for word in doc if word in model.wv] # Get individual embeddings into a list\n    # Consider implementing exception handling \n    if len(embeddings) > 0:\n        return np.mean(embeddings, axis=0) \n    else:\n        return np.zeros(model.vector_size)\n\n# Use previous functions to process user input into vector and use cosine \n# Similarity to find the most related courses\ndef recommend_courses(user_input, document_embeddings, data, top_n=5):\n    cleaned_input = clean_text(user_input)\n    input_embedding = get_document_embedding(cleaned_input, model)\n    similarities = cosine_similarity([input_embedding], document_embeddings)[0]\n    top_indices = np.argsort(similarities)[-top_n:][::-1]\n    recommendations = data.iloc[top_indices][['name', 'topic', 'link', 'provider']]\n    return recommendations\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T19:07:35.034169Z","iopub.execute_input":"2025-02-06T19:07:35.034938Z","iopub.status.idle":"2025-02-06T19:08:00.236492Z","shell.execute_reply.started":"2025-02-06T19:07:35.034906Z","shell.execute_reply":"2025-02-06T19:08:00.235251Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Experiment with other data\n# edx, coursera, harvard, mit ocw\n# https://sparkbyexamples.com/pandas/pandas-read-multiple-csv-files/#:~:text=Load%20each%20file%20into%20individual,each%20file%20individually%20if%20needed.\n\n# Normalize/clean course data to the name, topic, link, text format for now\n\ndataMit = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\")\n# print(dataMit.head())\ndataMit.columns = map(str.lower, dataMit.columns)\ndataMit.rename(columns={'name ': 'name'}, inplace=True)\ndataMit.rename(columns={'course link': 'link'}, inplace=True)\ndataMit['text'] = dataMit['name'] + \" \" + dataMit['topic'] \ndataMit['provider'] = 'Massachussets Institute of Technology'\ndataMit = dataMit[['name', 'topic', 'link', 'provider', 'text']]\n\n\ndataHarvard = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\")\n# print(dataHarvard.head())\ndataHarvard.columns = map(str.lower, dataHarvard.columns)\ndataHarvard.rename(columns={'link to course': 'link', 'about': 'topic'}, inplace=True)\ndataHarvard = dataHarvard[dataHarvard['price'] == 'Free']\ndataHarvard['text'] = dataHarvard['name'] + \" \" + dataHarvard['topic'] \ndataHarvard['provider'] = 'Harvard University'\ndataHarvard = dataHarvard[['name', 'topic', 'link', 'provider', 'text']]\n\n\ndataEdx = pd.read_csv(\"/kaggle/input/edx-courses-dataset-2021/EdX.csv\")\n# print(dataEdx.head())\ndataEdx.columns = map(str.lower, dataEdx.columns)\ndataEdx[\"topic\"] = dataEdx['about'] + '. ' + dataEdx['course description']\ndataEdx[\"provider\"] = 'edX - ' + dataEdx['university']\ndataEdx['text'] = dataEdx['name'] + \" \" + dataEdx[\"topic\"]\ndataEdx = dataEdx[['name', 'topic', 'link', 'provider', 'text']]\n\n\n# Udemy\ndataUdemy = pd.read_csv(\"/kaggle/input/udemy-course-dataset-categories-ratings-and-trends/udemy_courses.csv\")\ndataUdemy.columns = map(str.lower, dataUdemy.columns)\ndataUdemy.rename(columns={\n    'title': 'name',\n    'headline': 'topic',\n    'url': 'link',\n}, inplace=True)\n# only keep free courses\ndataUdemy = dataUdemy[dataUdemy['is_paid'] == False]\n# Since Udemy courses are user generated, filter only courses with rating over 4.5\ndataUdemy['provider'] = 'Udemy'\ndataUdemy = dataUdemy[dataUdemy['rating'] > 4.5 ]\ndataUdemy['text'] = dataUdemy['name'] + \" \" + dataUdemy['topic']\ndataUdemy = dataUdemy[['name', 'topic', 'link', 'provider', 'text']]\nprint(dataUdemy.head())\n\n\n# Coursera\ndataCoursera = pd.read_csv(\"/kaggle/input/coursera-free-courses-dataset/coursera.csv\")\ndataCoursera.rename(columns={\n    'title': 'name',\n    'skills': 'topic',\n    'url': 'link',\n}, inplace=True)\ndataCoursera = dataCoursera[dataCoursera['price'] == 'Free']\ndataCoursera['text'] = dataCoursera['name'] + \" \" + np.where(pd.notna(dataCoursera['topic']), dataCoursera['topic'], \"\")\n\ndataCoursera['provider'] = 'Coursera - ' + dataCoursera['course_by']\ndataCoursera = dataCoursera[['name', 'topic', 'link', 'provider', 'text']]\ndataCoursera = dataCoursera.fillna(\"\") # Fill null values\n\n# print(dataCoursera.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T19:08:04.504907Z","iopub.execute_input":"2025-02-06T19:08:04.505706Z","iopub.status.idle":"2025-02-06T19:08:10.981964Z","shell.execute_reply.started":"2025-02-06T19:08:04.505658Z","shell.execute_reply":"2025-02-06T19:08:10.980711Z"}},"outputs":[{"name":"stdout","text":"                                                    name  \\\n26443                           Stock Market Foundations   \n26445  The Complete Course On Understanding Blockchai...   \n26446  Bitcoin or How I Learned to Stop Worrying and ...   \n26448  Blockchain cryptocurrency course 101 for absol...   \n26449  Trading Options For Consistent Returns: Option...   \n\n                                                   topic  \\\n26443  The Market isn't a Mystery, It’s a Playground....   \n26445  A Beginner's Guide to Authentic Knowledge on B...   \n26446  The definitive guide to understand what the bi...   \n26448  A complete guide to anyone who wants to really...   \n26449                     The Foundation For Consistency   \n\n                                                    link provider  \\\n26443  https://www.udemy.com/course/how-to-invest-in-...    Udemy   \n26445  https://www.udemy.com/course/understanding-blo...    Udemy   \n26446  https://www.udemy.com/course/bitcoin-or-how-i-...    Udemy   \n26448  https://www.udemy.com/course/blockchain-crypto...    Udemy   \n26449  https://www.udemy.com/course/trading-options-f...    Udemy   \n\n                                                    text  \n26443  Stock Market Foundations The Market isn't a My...  \n26445  The Complete Course On Understanding Blockchai...  \n26446  Bitcoin or How I Learned to Stop Worrying and ...  \n26448  Blockchain cryptocurrency course 101 for absol...  \n26449  Trading Options For Consistent Returns: Option...  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Create a Combined Dataframe\ndata = pd.concat([dataUdemy, dataMit, dataHarvard, dataEdx, dataCoursera])\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T19:08:18.186805Z","iopub.execute_input":"2025-02-06T19:08:18.187417Z","iopub.status.idle":"2025-02-06T19:08:18.213014Z","shell.execute_reply.started":"2025-02-06T19:08:18.187363Z","shell.execute_reply":"2025-02-06T19:08:18.211241Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                    name  \\\n26443                           Stock Market Foundations   \n26445  The Complete Course On Understanding Blockchai...   \n26446  Bitcoin or How I Learned to Stop Worrying and ...   \n26448  Blockchain cryptocurrency course 101 for absol...   \n26449  Trading Options For Consistent Returns: Option...   \n\n                                                   topic  \\\n26443  The Market isn't a Mystery, It’s a Playground....   \n26445  A Beginner's Guide to Authentic Knowledge on B...   \n26446  The definitive guide to understand what the bi...   \n26448  A complete guide to anyone who wants to really...   \n26449                     The Foundation For Consistency   \n\n                                                    link provider  \\\n26443  https://www.udemy.com/course/how-to-invest-in-...    Udemy   \n26445  https://www.udemy.com/course/understanding-blo...    Udemy   \n26446  https://www.udemy.com/course/bitcoin-or-how-i-...    Udemy   \n26448  https://www.udemy.com/course/blockchain-crypto...    Udemy   \n26449  https://www.udemy.com/course/trading-options-f...    Udemy   \n\n                                                    text  \n26443  Stock Market Foundations The Market isn't a My...  \n26445  The Complete Course On Understanding Blockchai...  \n26446  Bitcoin or How I Learned to Stop Worrying and ...  \n26448  Blockchain cryptocurrency course 101 for absol...  \n26449  Trading Options For Consistent Returns: Option...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n      <th>provider</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26443</th>\n      <td>Stock Market Foundations</td>\n      <td>The Market isn't a Mystery, It’s a Playground....</td>\n      <td>https://www.udemy.com/course/how-to-invest-in-...</td>\n      <td>Udemy</td>\n      <td>Stock Market Foundations The Market isn't a My...</td>\n    </tr>\n    <tr>\n      <th>26445</th>\n      <td>The Complete Course On Understanding Blockchai...</td>\n      <td>A Beginner's Guide to Authentic Knowledge on B...</td>\n      <td>https://www.udemy.com/course/understanding-blo...</td>\n      <td>Udemy</td>\n      <td>The Complete Course On Understanding Blockchai...</td>\n    </tr>\n    <tr>\n      <th>26446</th>\n      <td>Bitcoin or How I Learned to Stop Worrying and ...</td>\n      <td>The definitive guide to understand what the bi...</td>\n      <td>https://www.udemy.com/course/bitcoin-or-how-i-...</td>\n      <td>Udemy</td>\n      <td>Bitcoin or How I Learned to Stop Worrying and ...</td>\n    </tr>\n    <tr>\n      <th>26448</th>\n      <td>Blockchain cryptocurrency course 101 for absol...</td>\n      <td>A complete guide to anyone who wants to really...</td>\n      <td>https://www.udemy.com/course/blockchain-crypto...</td>\n      <td>Udemy</td>\n      <td>Blockchain cryptocurrency course 101 for absol...</td>\n    </tr>\n    <tr>\n      <th>26449</th>\n      <td>Trading Options For Consistent Returns: Option...</td>\n      <td>The Foundation For Consistency</td>\n      <td>https://www.udemy.com/course/trading-options-f...</td>\n      <td>Udemy</td>\n      <td>Trading Options For Consistent Returns: Option...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# The list of tokenized sentences, ie our Corpus \ndata['cleaned_text'] = data['text'].apply(clean_text) # Add clean text column to dataframe\ndata['cleaned_text'].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T19:08:27.089760Z","iopub.execute_input":"2025-02-06T19:08:27.090159Z","iopub.status.idle":"2025-02-06T19:09:00.316844Z","shell.execute_reply.started":"2025-02-06T19:08:27.090125Z","shell.execute_reply":"2025-02-06T19:09:00.315888Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"26443    [stock, market, foundation, market, isnt, myst...\n26445    [complete, course, understanding, blockchain, ...\n26446    [bitcoin, learned, stop, worrying, love, crypt...\n26448    [blockchain, cryptocurrency, course, 101, abso...\n26449    [trading, option, consistent, return, option, ...\nName: cleaned_text, dtype: object"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Corpus = list of tokenized sentences (already cleaned)\ncorpus = data['cleaned_text'].tolist()\nprint(corpus[0])\n\n# Train Word2Vec\nmodel = Word2Vec(\n    sentences=corpus,\n    vector_size=80,\n    window=5,       # Larger window for broader context\n    min_count=8,    # Ignore very rare words\n    workers=4,\n    epochs=10\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T19:11:48.673422Z","iopub.execute_input":"2025-02-06T19:11:48.673784Z","iopub.status.idle":"2025-02-06T19:11:50.019368Z","shell.execute_reply.started":"2025-02-06T19:11:48.673759Z","shell.execute_reply":"2025-02-06T19:11:50.018258Z"}},"outputs":[{"name":"stdout","text":"['stock', 'market', 'foundation', 'market', 'isnt', 'mystery', 'playgroundlearn', 'rule', 'learn', 'play']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Get a list of the document embedding vector for each sentence in the cleaned text data. The indices will be aligned with the original course rows in dataframe\ndocument_embeddings = [get_document_embedding(doc, model)\n                      for doc in data['cleaned_text']]\nprint(f'list of sentence vectors/sentences: {len(document_embeddings)}')\nprint(f'each sentence has {document_embeddings[0].shape} dimensions')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T19:11:51.518381Z","iopub.execute_input":"2025-02-06T19:11:51.518758Z","iopub.status.idle":"2025-02-06T19:11:51.990537Z","shell.execute_reply.started":"2025-02-06T19:11:51.518731Z","shell.execute_reply":"2025-02-06T19:11:51.989463Z"}},"outputs":[{"name":"stdout","text":"list of sentence vectors/sentences: 5989\neach sentence has (80,) dimensions\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# User interface (abstracted away)\nuser_input = \"Lagrange Multipliers\"\nrecommendations = recommend_courses(user_input, document_embeddings, data)\nrecommendations.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T19:12:30.751641Z","iopub.execute_input":"2025-02-06T19:12:30.751980Z","iopub.status.idle":"2025-02-06T19:12:30.775844Z","shell.execute_reply.started":"2025-02-06T19:12:30.751954Z","shell.execute_reply":"2025-02-06T19:12:30.774557Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                  name  \\\n987       eHealth: More than just an electronic record   \n347  Godzilla and the Bullet Train: Technology and ...   \n338                      Biomolecular Feedback Systems   \n339                             American Popular Music   \n340                   Victorian Literature and Culture   \n\n                                            topic  \\\n987                                                 \n347             Media Studies, Fine Arts, Society   \n338  Engineering, Science, Mechanical Engineering   \n339               Music, Fine Arts, Music History   \n340               Humanities, Literature, History   \n\n                                                  link  \\\n987             https://www.coursera.org/learn/ehealth   \n347  https://ocw.mit.edu/courses/sts-s28-godzilla-a...   \n338  https://ocw.mit.edu/courses/2-18-biomolecular-...   \n339  https://ocw.mit.edu/courses/21m-295-american-p...   \n340  https://ocw.mit.edu/courses/21l-481-victorian-...   \n\n                                  provider  \n987    Coursera - The University of Sydney  \n347  Massachussets Institute of Technology  \n338  Massachussets Institute of Technology  \n339  Massachussets Institute of Technology  \n340  Massachussets Institute of Technology  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n      <th>provider</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>987</th>\n      <td>eHealth: More than just an electronic record</td>\n      <td></td>\n      <td>https://www.coursera.org/learn/ehealth</td>\n      <td>Coursera - The University of Sydney</td>\n    </tr>\n    <tr>\n      <th>347</th>\n      <td>Godzilla and the Bullet Train: Technology and ...</td>\n      <td>Media Studies, Fine Arts, Society</td>\n      <td>https://ocw.mit.edu/courses/sts-s28-godzilla-a...</td>\n      <td>Massachussets Institute of Technology</td>\n    </tr>\n    <tr>\n      <th>338</th>\n      <td>Biomolecular Feedback Systems</td>\n      <td>Engineering, Science, Mechanical Engineering</td>\n      <td>https://ocw.mit.edu/courses/2-18-biomolecular-...</td>\n      <td>Massachussets Institute of Technology</td>\n    </tr>\n    <tr>\n      <th>339</th>\n      <td>American Popular Music</td>\n      <td>Music, Fine Arts, Music History</td>\n      <td>https://ocw.mit.edu/courses/21m-295-american-p...</td>\n      <td>Massachussets Institute of Technology</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>Victorian Literature and Culture</td>\n      <td>Humanities, Literature, History</td>\n      <td>https://ocw.mit.edu/courses/21l-481-victorian-...</td>\n      <td>Massachussets Institute of Technology</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"# Important Notes\n\n* Original Source: https://www.kaggle.com/code/shtrausslearning/nlp-edx-course-recommendations\n* DeepSeek AI for original base which also calls the document embeddings for the input\n* I have added comments to better study and understand the code as a base to build off of\n* Instead of directly matching to a course index in the dataset which limits the use of the model\n\n# Todo (to better understand and be able to present on this topic)\n\n* Study cosine similarity\\\n* Word2Vec and stopwords/lemmatization\n* Coursera, futurelearn, udemy\n* Build a frontend for the app\n\n# Improvements\n\nreshaped corpus as list instead of series, increased context window, ","metadata":{}}]}