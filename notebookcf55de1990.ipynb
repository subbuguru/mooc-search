{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3051937,"sourceType":"datasetVersion","datasetId":1868643},{"sourceId":7055553,"sourceType":"datasetVersion","datasetId":4057183},{"sourceId":9279572,"sourceType":"datasetVersion","datasetId":5456599}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:10:35.468234Z","iopub.execute_input":"2025-01-29T17:10:35.468694Z","iopub.status.idle":"2025-01-29T17:10:35.494550Z","shell.execute_reply.started":"2025-01-29T17:10:35.468662Z","shell.execute_reply":"2025-01-29T17:10:35.493472Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/multi-platform-online-courses-dataset/edx.csv\n/kaggle/input/multi-platform-online-courses-dataset/skillshare.csv\n/kaggle/input/multi-platform-online-courses-dataset/Udemy.csv\n/kaggle/input/multi-platform-online-courses-dataset/Coursera.csv\n/kaggle/input/edx-courses-dataset-2021/EdX.csv\n/kaggle/input/dataset-of-1200-coursera-courses/edx.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Barkeley_extension.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Oxford.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Stanford.csv\n/kaggle/input/dataset-of-1200-coursera-courses/udacity.csv\n/kaggle/input/dataset-of-1200-coursera-courses/alison.csv\n/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\n/kaggle/input/dataset-of-1200-coursera-courses/london school of economics.csv\n/kaggle/input/dataset-of-1200-coursera-courses/coursera_update.csv\n/kaggle/input/dataset-of-1200-coursera-courses/pluralsight.csv\n/kaggle/input/dataset-of-1200-coursera-courses/futurelearn.csv\n/kaggle/input/dataset-of-1200-coursera-courses/swayam.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Install NLTK\n!pip list | grep nltk\n\nimport nltk\n\nnltk.download('punkt')  \nnltk.download('wordnet')  \n\n# Unzip per this stackoverflow: https://stackoverflow.com/questions/73849624/getting-error-while-submitting-notebook-on-kaggle-even-after-importing-nltk-libr\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:10:39.671030Z","iopub.execute_input":"2025-01-29T17:10:39.671439Z","iopub.status.idle":"2025-01-29T17:11:12.734251Z","shell.execute_reply.started":"2025-01-29T17:10:39.671404Z","shell.execute_reply":"2025-01-29T17:11:12.732572Z"}},"outputs":[{"name":"stdout","text":"nltk                               3.2.4\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\nreplace /usr/share/nltk_data/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Setup\n\nimport pandas as pd\nimport numpy as np\nfrom gensim.models import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity \nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nimport re\n\n# Clean text \ndef clean_text(text):\n    lemma = WordNetLemmatizer() # lemmatizer\n    text = re.sub(\"[^A-Za-z1-9 ]\", \"\", text)\n    text = text.lower()\n    tokens = word_tokenize(text) # look into this tokenization\n    tokens = [lemma.lemmatize(word) for word in tokens # lemmatize words and remove stopwords \n                if word not in stopwords.words(\"english\")]\n    return tokens\n\n\n# Get the sentence embeddings for each course and user input with this function\n# First get the word embeddings and average them out for the sentence (aka course/input)\n# overall embedding\n\ndef get_document_embedding(doc, model):\n    embeddings = [model.wv[word] for word in doc if word in model.wv] # Get individual embeddings into a list\n    # Consider implementing exception handling \n    if len(embeddings) > 0:\n        return np.mean(embeddings, axis=0) #How does np.mean work\n    else:\n        return np.zeros(model.vector_size)\n\n# Use previous functions to process user input into vector and use cosine \n# Similarity to find the most related courses\ndef recommend_courses(user_input, document_embeddings, data, top_n=5):\n    cleaned_input = clean_text(user_input)\n    input_embedding = get_document_embedding(cleaned_input, word2vec_model)\n    similarities = cosine_similarity([input_embedding], document_embeddings)[0]\n    top_indices = np.argsort(similarities)[-top_n:][::-1]\n    recommendations = data.iloc[top_indices][['name', 'university', 'difficulty level', 'course description', 'link']]\n    return recommendations\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:17:31.947030Z","iopub.execute_input":"2025-01-30T19:17:31.947407Z","iopub.status.idle":"2025-01-30T19:17:50.914672Z","shell.execute_reply.started":"2025-01-30T19:17:31.947381Z","shell.execute_reply":"2025-01-30T19:17:50.913705Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Experiment with other data\n# edx, coursera, harvard, mit ocw\n# https://sparkbyexamples.com/pandas/pandas-read-multiple-csv-files/#:~:text=Load%20each%20file%20into%20individual,each%20file%20individually%20if%20needed.\n\n# Normalize/clean course data to the name, topic, link, text format for now\n\ndataMit = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\")\ndataMit.columns = map(str.lower, dataMit.columns)\ndataMit.rename(columns={'name ': 'name'}, inplace=True)\ndataMit = dataMit.drop(columns=['sub category', 'category', 'resource type', 'course code', 'instructure'])\ndataMit.rename(columns={'course link': 'link'}, inplace=True)\ndataMit['text'] = dataMit['name'] + \" \" + dataMit['topic'] \nprint(column_names)\n\ndataMit = dataMit[['name', 'topic', 'link']]\nprint(dataMit.head())\n\n\ndataHarvard = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\")\ndataHarvard.columns = map(str.lower, dataHarvard.columns)\ndataHarvard.rename(columns={'link to course': 'link', 'about': 'topic'}, inplace=True)\n# Remove rows where the price is not 'Free' (gpt code)\ndataHarvard = dataHarvard[dataHarvard['price'] == 'Free']\n# Select only the columns 'name', 'topic', and 'link'\ndataHarvard = dataHarvard[['name', 'topic', 'link']]\ndataHarvard['text'] = dataHarvard['name'] + \" \" + dataHarvard['topic'] \n# print(dataHarvard.head())\n\n# Coursera data\n\n# Read in 2021 EdXdata\ndataEdx = pd.read_csv(\"/kaggle/input/edx-courses-dataset-2021/EdX.csv\")\ndataEdx.columns = map(str.lower, dataEdx.columns)\ndataEdx[\"topic\"] = dataEdx['about'] + '. ' + dataEdx['course description']\ndataEdx = dataEdx[['name', 'topic', 'link']]\ndataEdx['text'] = dataEdx['name'] + \" \" + dataEdx[\"topic\"]\n# dataEdx.head()\n\n# Read in ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:50:42.441896Z","iopub.execute_input":"2025-01-30T19:50:42.442248Z","iopub.status.idle":"2025-01-30T19:50:42.518917Z","shell.execute_reply.started":"2025-01-30T19:50:42.442222Z","shell.execute_reply":"2025-01-30T19:50:42.517741Z"}},"outputs":[{"name":"stdout","text":"link, name, topic, text\n                        name                                          topic  \\\n0           Energy Economics             Science, Economics, Social Science   \n1    Identity and Difference          Social Science, Society, Anthropology   \n2   Single Variable Calculus  Mathematics, Differential Equations, Calculus   \n3  Libertarianism in History            Humanities, History, Social Science   \n4       Introductory Biology          Science, Health and Medicine, Biology   \n\n                                                link  \n0  https://ocw.mit.edu/courses/14-44-energy-econo...  \n1  https://ocw.mit.edu/courses/21a-218j-identity-...  \n2  https://ocw.mit.edu/courses/18-01-single-varia...  \n3  https://ocw.mit.edu/courses/21h-181-libertaria...  \n4  https://ocw.mit.edu/courses/7-016-introductory...  \n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"# Create a Combined Dataframe\ndata = pd.concat([dataMit, dataHarvard, dataEdx])\n#data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:48:43.634962Z","iopub.execute_input":"2025-01-30T19:48:43.635377Z","iopub.status.idle":"2025-01-30T19:48:43.650535Z","shell.execute_reply.started":"2025-01-30T19:48:43.635345Z","shell.execute_reply":"2025-01-30T19:48:43.649445Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                        name                                          topic  \\\n0           Energy Economics             Science, Economics, Social Science   \n1    Identity and Difference          Social Science, Society, Anthropology   \n2   Single Variable Calculus  Mathematics, Differential Equations, Calculus   \n3  Libertarianism in History            Humanities, History, Social Science   \n4       Introductory Biology          Science, Health and Medicine, Biology   \n\n                                                link text  \n0  https://ocw.mit.edu/courses/14-44-energy-econo...  NaN  \n1  https://ocw.mit.edu/courses/21a-218j-identity-...  NaN  \n2  https://ocw.mit.edu/courses/18-01-single-varia...  NaN  \n3  https://ocw.mit.edu/courses/21h-181-libertaria...  NaN  \n4  https://ocw.mit.edu/courses/7-016-introductory...  NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Energy Economics</td>\n      <td>Science, Economics, Social Science</td>\n      <td>https://ocw.mit.edu/courses/14-44-energy-econo...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Identity and Difference</td>\n      <td>Social Science, Society, Anthropology</td>\n      <td>https://ocw.mit.edu/courses/21a-218j-identity-...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Single Variable Calculus</td>\n      <td>Mathematics, Differential Equations, Calculus</td>\n      <td>https://ocw.mit.edu/courses/18-01-single-varia...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Libertarianism in History</td>\n      <td>Humanities, History, Social Science</td>\n      <td>https://ocw.mit.edu/courses/21h-181-libertaria...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Introductory Biology</td>\n      <td>Science, Health and Medicine, Biology</td>\n      <td>https://ocw.mit.edu/courses/7-016-introductory...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"# The list of tokenized sentences, ie our Corpus \ndata['cleaned_text'] = data['text'].apply(clean_text) # Add clean text column to dataframe\ndata['cleaned_text'].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:13:23.990124Z","iopub.execute_input":"2025-01-29T17:13:23.991429Z","iopub.status.idle":"2025-01-29T17:13:50.264340Z","shell.execute_reply.started":"2025-01-29T17:13:23.991382Z","shell.execute_reply":"2025-01-29T17:13:50.263048Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"0    [energy, economics, science, economics, social...\n1    [identity, difference, social, science, societ...\n2    [single, variable, calculus, mathematics, diff...\n3    [libertarianism, history, humanity, history, s...\n4    [introductory, biology, science, health, medic...\nName: cleaned_text, dtype: object"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"# Train the model (look into how this works/can be configured more specifically\n# and see the todo list)\n\nword2vec_model = Word2Vec(\n    sentences=data['cleaned_text'],\n    vector_size=100,\n    min_count=1,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:15:36.721677Z","iopub.execute_input":"2025-01-29T17:15:36.722114Z","iopub.status.idle":"2025-01-29T17:15:37.781437Z","shell.execute_reply.started":"2025-01-29T17:15:36.722079Z","shell.execute_reply":"2025-01-29T17:15:37.780522Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Get a list of the document embedding vector for each sentence in the cleaned text data\ndocument_embeddings = [get_document_embedding(doc, word2vec_model)\n                      for doc in data['cleaned_text']]\ndocument_embeddings[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:15:50.493696Z","iopub.execute_input":"2025-01-29T17:15:50.494034Z","iopub.status.idle":"2025-01-29T17:15:50.851591Z","shell.execute_reply.started":"2025-01-29T17:15:50.494008Z","shell.execute_reply":"2025-01-29T17:15:50.850425Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"array([-0.33050957,  1.3129758 , -0.23675087, -0.39530584,  0.32115155,\n       -0.28052858,  0.12256752,  1.9098924 , -0.13483056, -0.6778844 ,\n        0.4702141 , -1.0808438 , -0.04577271, -0.02055188,  0.18441686,\n       -0.00902548,  1.696166  ,  0.0675119 , -0.74802935, -1.2348891 ,\n       -0.06763209, -0.7299306 ,  0.91267395, -0.21569045,  0.19937897,\n        0.76901245,  0.30119827, -0.3375313 , -0.35949424,  0.9457317 ,\n        0.50089926, -0.6765849 , -0.48110262, -0.78745323, -0.3824605 ,\n        0.5359365 ,  1.2158784 ,  0.09308362, -0.20864157,  0.27100348,\n        1.008581  , -0.40488777, -0.24397121, -0.41719952,  0.04743673,\n        0.5546692 , -0.6616823 , -0.4978992 ,  0.39706534,  1.6474438 ,\n        0.8744562 , -1.153931  , -0.9011733 , -0.0357539 , -1.4920715 ,\n        0.0615241 ,  0.94522655,  0.57195944,  0.14965867, -0.44829467,\n       -0.35497734, -0.22344853,  0.9656228 , -0.04121501, -0.50352687,\n        0.73420733,  0.2710003 , -0.02785451, -0.6998839 ,  0.40383244,\n        0.8361176 ,  0.32250124,  0.5484312 ,  0.6482623 ,  0.60378414,\n       -0.25559038,  0.65507966,  0.18809915, -0.67361957,  0.8706136 ,\n       -1.0049531 , -0.32536834, -0.33557042,  0.41593346, -0.80971223,\n       -0.9811196 ,  0.11819215,  0.0573844 , -0.12329156, -0.0503426 ,\n       -0.03819844,  0.82838213,  0.12991284, -0.04955365,  0.57804686,\n        0.17322424,  2.376192  , -0.93134844, -0.3380482 ,  0.26307708],\n      dtype=float32)"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# User interface (abstracted away)\nuser_input = \"cars\"\nrecommendations = recommend_courses(user_input, document_embeddings, data)\nrecommendations.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:16:41.643296Z","iopub.execute_input":"2025-01-29T17:16:41.643715Z","iopub.status.idle":"2025-01-29T17:16:41.664757Z","shell.execute_reply.started":"2025-01-29T17:16:41.643686Z","shell.execute_reply":"2025-01-29T17:16:41.663717Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"                                                  name          university  \\\n45             Energy Within Environmental Constraints  Harvard University   \n429                          Origins of the Human Mind    Kyoto University   \n37                                Boosting Your Energy                 NaN   \n380                              One Planet, One Ocean         SDG Academy   \n136  Literati China: Examinations, Neo-Confucianism...                 NaN   \n\n    difficulty level                                 course description  \\\n45          Beginner  Humanity faces an immense challenge: providing...   \n429         Beginner  The human mind is an evolutionary product, jus...   \n37               NaN                                                NaN   \n380     Intermediate  Is the ocean the real final frontier? Humans h...   \n136              NaN                                                NaN   \n\n                                                  link  \n45   https://www.edx.org/course/energy-within-envir...  \n429  https://www.edx.org/course/origins-of-the-huma...  \n37                                                 NaN  \n380    https://www.edx.org/course/one-planet-one-ocean  \n136                                                NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>university</th>\n      <th>difficulty level</th>\n      <th>course description</th>\n      <th>link</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45</th>\n      <td>Energy Within Environmental Constraints</td>\n      <td>Harvard University</td>\n      <td>Beginner</td>\n      <td>Humanity faces an immense challenge: providing...</td>\n      <td>https://www.edx.org/course/energy-within-envir...</td>\n    </tr>\n    <tr>\n      <th>429</th>\n      <td>Origins of the Human Mind</td>\n      <td>Kyoto University</td>\n      <td>Beginner</td>\n      <td>The human mind is an evolutionary product, jus...</td>\n      <td>https://www.edx.org/course/origins-of-the-huma...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Boosting Your Energy</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>One Planet, One Ocean</td>\n      <td>SDG Academy</td>\n      <td>Intermediate</td>\n      <td>Is the ocean the real final frontier? Humans h...</td>\n      <td>https://www.edx.org/course/one-planet-one-ocean</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>Literati China: Examinations, Neo-Confucianism...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"markdown","source":"# Important Notes\n\n* Original Source: https://www.kaggle.com/code/shtrausslearning/nlp-edx-course-recommendations\n* DeepSeek AI for original base which also calls the document embeddings for the input\n* I have added comments to better study and understand the code as a base to build off of\n* Instead of directly matching to a course index in the dataset which limits the use of the model\n\n# Todo (to better understand and be able to present on this topic)\n\n* Study cosine similarity\\\n* Word2Vec and stopwords/lemmatization","metadata":{}}]}