{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3051937,"sourceType":"datasetVersion","datasetId":1868643},{"sourceId":7055553,"sourceType":"datasetVersion","datasetId":4057183},{"sourceId":9279572,"sourceType":"datasetVersion","datasetId":5456599}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T22:20:32.790361Z","iopub.execute_input":"2025-02-04T22:20:32.790605Z","iopub.status.idle":"2025-02-04T22:20:34.075172Z","shell.execute_reply.started":"2025-02-04T22:20:32.790582Z","shell.execute_reply":"2025-02-04T22:20:34.074070Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/multi-platform-online-courses-dataset/edx.csv\n/kaggle/input/multi-platform-online-courses-dataset/skillshare.csv\n/kaggle/input/multi-platform-online-courses-dataset/Udemy.csv\n/kaggle/input/multi-platform-online-courses-dataset/Coursera.csv\n/kaggle/input/edx-courses-dataset-2021/EdX.csv\n/kaggle/input/dataset-of-1200-coursera-courses/edx.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Barkeley_extension.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Oxford.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Stanford.csv\n/kaggle/input/dataset-of-1200-coursera-courses/udacity.csv\n/kaggle/input/dataset-of-1200-coursera-courses/alison.csv\n/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\n/kaggle/input/dataset-of-1200-coursera-courses/london school of economics.csv\n/kaggle/input/dataset-of-1200-coursera-courses/coursera_update.csv\n/kaggle/input/dataset-of-1200-coursera-courses/pluralsight.csv\n/kaggle/input/dataset-of-1200-coursera-courses/futurelearn.csv\n/kaggle/input/dataset-of-1200-coursera-courses/swayam.csv\n/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install NLTK\n!pip list | grep nltk\n! pip install -U kaleido\nimport nltk\n\nnltk.download('punkt')  \nnltk.download('wordnet')  \n\n# Unzip per this stackoverflow: https://stackoverflow.com/questions/73849624/getting-error-while-submitting-notebook-on-kaggle-even-after-importing-nltk-libr\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T22:22:50.079728Z","iopub.execute_input":"2025-02-04T22:22:50.080077Z","iopub.status.idle":"2025-02-04T22:23:01.241669Z","shell.execute_reply.started":"2025-02-04T22:22:50.080049Z","shell.execute_reply":"2025-02-04T22:23:01.240148Z"}},"outputs":[{"name":"stdout","text":"nltk                               3.2.4\nCollecting kaleido\n  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\nDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: kaleido\nSuccessfully installed kaleido-0.2.1\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Setup\n\nimport pandas as pd\nimport numpy as np\nfrom gensim.models import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity \nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nimport re\n\n# Clean text \ndef clean_text(text):\n    lemma = WordNetLemmatizer() # lemmatizer\n    text = re.sub(\"[^A-Za-z0-9 ]\", \"\", text)\n    text = text.lower()\n    tokens = word_tokenize(text) # look into this tokenization\n    tokens = [lemma.lemmatize(word) for word in tokens # lemmatize words and remove stopwords \n                if word not in stopwords.words(\"english\")]\n    return tokens\n\n\n# Get the sentence embeddings for each course and user input with this function\n# First get the word embeddings and average them out for the sentence (aka course/input)\n# overall embedding\n\ndef get_document_embedding(doc, model):\n    embeddings = [model.wv[word] for word in doc if word in model.wv] # Get individual embeddings into a list\n    # Consider implementing exception handling \n    if len(embeddings) > 0:\n        return np.mean(embeddings, axis=0) \n    else:\n        return np.zeros(model.vector_size)\n\n# Use previous functions to process user input into vector and use cosine \n# Similarity to find the most related courses\ndef recommend_courses(user_input, document_embeddings, data, top_n=5):\n    cleaned_input = clean_text(user_input)\n    input_embedding = get_document_embedding(cleaned_input, model)\n    similarities = cosine_similarity([input_embedding], document_embeddings)[0]\n    top_indices = np.argsort(similarities)[-top_n:][::-1]\n    recommendations = data.iloc[top_indices][['name', 'topic', 'link', 'provider']]\n    return recommendations\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T22:41:55.029727Z","iopub.execute_input":"2025-02-04T22:41:55.030261Z","iopub.status.idle":"2025-02-04T22:41:55.041521Z","shell.execute_reply.started":"2025-02-04T22:41:55.030222Z","shell.execute_reply":"2025-02-04T22:41:55.039903Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Experiment with other data\n# edx, coursera, harvard, mit ocw\n# https://sparkbyexamples.com/pandas/pandas-read-multiple-csv-files/#:~:text=Load%20each%20file%20into%20individual,each%20file%20individually%20if%20needed.\n\n# Normalize/clean course data to the name, topic, link, text format for now\n\ndataMit = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/MIT ocw.csv\")\n# print(dataMit.head())\ndataMit.columns = map(str.lower, dataMit.columns)\ndataMit.rename(columns={'name ': 'name'}, inplace=True)\ndataMit.rename(columns={'course link': 'link'}, inplace=True)\ndataMit = dataMit[['name', 'topic', 'link']]\ndataMit['text'] = dataMit['name'] + \" \" + dataMit['topic'] \ndataMit['provider'] = 'Massachussets Institute of Technology'\n\ndataHarvard = pd.read_csv(\"/kaggle/input/dataset-of-1200-coursera-courses/Harvard_university.csv\")\n# print(dataHarvard.head())\ndataHarvard.columns = map(str.lower, dataHarvard.columns)\ndataHarvard.rename(columns={'link to course': 'link', 'about': 'topic'}, inplace=True)\ndataHarvard = dataHarvard[dataHarvard['price'] == 'Free']\ndataHarvard = dataHarvard[['name', 'topic', 'link']]\ndataHarvard['text'] = dataHarvard['name'] + \" \" + dataHarvard['topic'] \ndataHarvard['provider'] = 'Harvard University'\n\ndataEdx = pd.read_csv(\"/kaggle/input/edx-courses-dataset-2021/EdX.csv\")\n# print(dataEdx.head())\ndataEdx.columns = map(str.lower, dataEdx.columns)\ndataEdx[\"topic\"] = dataEdx['about'] + '. ' + dataEdx['course description']\ndataEdx[\"provider\"] = 'edX - ' + dataEdx['university']\ndataEdx = dataEdx[['name', 'topic', 'link', 'provider']]\ndataEdx['text'] = dataEdx['name'] + \" \" + dataEdx[\"topic\"]\nprint(dataEdx.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T22:53:57.597311Z","iopub.execute_input":"2025-02-04T22:53:57.597667Z","iopub.status.idle":"2025-02-04T22:53:57.671337Z","shell.execute_reply.started":"2025-02-04T22:53:57.597638Z","shell.execute_reply":"2025-02-04T22:53:57.670294Z"}},"outputs":[{"name":"stdout","text":"                                                name  \\\n0                                How to Learn Online   \n1  Programming for Everybody (Getting Started wit...   \n2            CS50's Introduction to Computer Science   \n3                                 The Analytics Edge   \n4  Marketing Analytics: Marketing Measurement Str...   \n\n                                               topic  \\\n0  Learn essential strategies for successful onli...   \n1  This course is a \"no prerequisite\" introductio...   \n2  An introduction to the intellectual enterprise...   \n3  Through inspiring examples and stories, discov...   \n4  This course is part of a MicroMasters® Program...   \n\n                                                link  \\\n0     https://www.edx.org/course/how-to-learn-online   \n1  https://www.edx.org/course/programming-for-eve...   \n2  https://www.edx.org/course/cs50s-introduction-...   \n3      https://www.edx.org/course/the-analytics-edge   \n4  https://www.edx.org/course/marketing-analytics...   \n\n                                      provider  \\\n0                                    edX - edX   \n1             edX - The University of Michigan   \n2                     edX - Harvard University   \n3  edX - Massachusetts Institute of Technology   \n4     edX - University of California, Berkeley   \n\n                                                text  \n0  How to Learn Online Learn essential strategies...  \n1  Programming for Everybody (Getting Started wit...  \n2  CS50's Introduction to Computer Science An int...  \n3  The Analytics Edge Through inspiring examples ...  \n4  Marketing Analytics: Marketing Measurement Str...  \n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Create a Combined Dataframe\ndata = pd.concat([dataMit, dataHarvard, dataEdx])\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T22:54:01.872932Z","iopub.execute_input":"2025-02-04T22:54:01.873391Z","iopub.status.idle":"2025-02-04T22:54:01.887628Z","shell.execute_reply.started":"2025-02-04T22:54:01.873358Z","shell.execute_reply":"2025-02-04T22:54:01.886644Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                        name                                          topic  \\\n0           Energy Economics             Science, Economics, Social Science   \n1    Identity and Difference          Social Science, Society, Anthropology   \n2   Single Variable Calculus  Mathematics, Differential Equations, Calculus   \n3  Libertarianism in History            Humanities, History, Social Science   \n4       Introductory Biology          Science, Health and Medicine, Biology   \n\n                                                link  \\\n0  https://ocw.mit.edu/courses/14-44-energy-econo...   \n1  https://ocw.mit.edu/courses/21a-218j-identity-...   \n2  https://ocw.mit.edu/courses/18-01-single-varia...   \n3  https://ocw.mit.edu/courses/21h-181-libertaria...   \n4  https://ocw.mit.edu/courses/7-016-introductory...   \n\n                                                text  \\\n0  Energy Economics Science, Economics, Social Sc...   \n1  Identity and Difference Social Science, Societ...   \n2  Single Variable Calculus Mathematics, Differen...   \n3  Libertarianism in History Humanities, History,...   \n4  Introductory Biology Science, Health and Medic...   \n\n                                provider  \n0  Massachussets Institute of Technology  \n1  Massachussets Institute of Technology  \n2  Massachussets Institute of Technology  \n3  Massachussets Institute of Technology  \n4  Massachussets Institute of Technology  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n      <th>text</th>\n      <th>provider</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Energy Economics</td>\n      <td>Science, Economics, Social Science</td>\n      <td>https://ocw.mit.edu/courses/14-44-energy-econo...</td>\n      <td>Energy Economics Science, Economics, Social Sc...</td>\n      <td>Massachussets Institute of Technology</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Identity and Difference</td>\n      <td>Social Science, Society, Anthropology</td>\n      <td>https://ocw.mit.edu/courses/21a-218j-identity-...</td>\n      <td>Identity and Difference Social Science, Societ...</td>\n      <td>Massachussets Institute of Technology</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Single Variable Calculus</td>\n      <td>Mathematics, Differential Equations, Calculus</td>\n      <td>https://ocw.mit.edu/courses/18-01-single-varia...</td>\n      <td>Single Variable Calculus Mathematics, Differen...</td>\n      <td>Massachussets Institute of Technology</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Libertarianism in History</td>\n      <td>Humanities, History, Social Science</td>\n      <td>https://ocw.mit.edu/courses/21h-181-libertaria...</td>\n      <td>Libertarianism in History Humanities, History,...</td>\n      <td>Massachussets Institute of Technology</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Introductory Biology</td>\n      <td>Science, Health and Medicine, Biology</td>\n      <td>https://ocw.mit.edu/courses/7-016-introductory...</td>\n      <td>Introductory Biology Science, Health and Medic...</td>\n      <td>Massachussets Institute of Technology</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# The list of tokenized sentences, ie our Corpus \ndata['cleaned_text'] = data['text'].apply(clean_text) # Add clean text column to dataframe\ndata['cleaned_text'].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T22:42:24.077388Z","iopub.execute_input":"2025-02-04T22:42:24.077721Z","iopub.status.idle":"2025-02-04T22:42:46.388522Z","shell.execute_reply.started":"2025-02-04T22:42:24.077696Z","shell.execute_reply":"2025-02-04T22:42:46.387461Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"0    [energy, economics, science, economics, social...\n1    [identity, difference, social, science, societ...\n2    [single, variable, calculus, mathematics, diff...\n3    [libertarianism, history, humanity, history, s...\n4    [introductory, biology, science, health, medic...\nName: cleaned_text, dtype: object"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# Corpus = list of tokenized sentences (already cleaned)\ncorpus = data['cleaned_text'].tolist()\ncorpus[0]\n\n# Train Word2Vec\nmodel = Word2Vec(\n    sentences=corpus,\n    vector_size=100,\n    window=5,       # Larger window for broader context\n    min_count=5,    # Ignore very rare words\n    workers=4,\n    epochs=10\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T22:24:43.375454Z","iopub.execute_input":"2025-02-04T22:24:43.375832Z","iopub.status.idle":"2025-02-04T22:24:44.400237Z","shell.execute_reply.started":"2025-02-04T22:24:43.375799Z","shell.execute_reply":"2025-02-04T22:24:44.399034Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Get a list of the document embedding vector for each sentence in the cleaned text data. The indices will be aligned with the original course rows in dataframe\ndocument_embeddings = [get_document_embedding(doc, model)\n                      for doc in data['cleaned_text']]\nprint(f'list of sentence vectors/sentences: {len(document_embeddings)}')\nprint(f'each sentence has {document_embeddings[0].shape} dimensions')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T22:25:29.527894Z","iopub.execute_input":"2025-02-04T22:25:29.528339Z","iopub.status.idle":"2025-02-04T22:25:29.829432Z","shell.execute_reply.started":"2025-02-04T22:25:29.528304Z","shell.execute_reply":"2025-02-04T22:25:29.828214Z"}},"outputs":[{"name":"stdout","text":"list of sentence vectors/sentences: 3382\neach sentence has (100,) dimensions\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# User interface (abstracted away)\nuser_input = \"data analytics with python\"\nrecommendations = recommend_courses(user_input, document_embeddings, data)\nrecommendations.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T22:26:23.307416Z","iopub.execute_input":"2025-02-04T22:26:23.307799Z","iopub.status.idle":"2025-02-04T22:26:23.325071Z","shell.execute_reply.started":"2025-02-04T22:26:23.307767Z","shell.execute_reply":"2025-02-04T22:26:23.324112Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                               name  \\\n113          Data Science: R Basics   \n114     Data Science: Visualization   \n67   High-Dimensional Data Analysis   \n68   High-Dimensional Data Analysis   \n75       Analyzing Data with Python   \n\n                                                 topic  \\\n113  Build a foundation in R and learn how to wrang...   \n114  Learn basic data visualization principles and ...   \n67   A focus on several techniques that are widely ...   \n68   A focus on several techniques that are widely ...   \n75   In this course, you will learn how to analyze ...   \n\n                                                  link  \n113  https://pll.harvard.edu/course/data-science-r-...  \n114  https://pll.harvard.edu/course/data-science-vi...  \n67   https://pll.harvard.edu/course/data-analysis-l...  \n68   https://pll.harvard.edu/course/data-analysis-l...  \n75   https://www.edx.org/course/analyzing-data-with...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>topic</th>\n      <th>link</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>113</th>\n      <td>Data Science: R Basics</td>\n      <td>Build a foundation in R and learn how to wrang...</td>\n      <td>https://pll.harvard.edu/course/data-science-r-...</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>Data Science: Visualization</td>\n      <td>Learn basic data visualization principles and ...</td>\n      <td>https://pll.harvard.edu/course/data-science-vi...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>High-Dimensional Data Analysis</td>\n      <td>A focus on several techniques that are widely ...</td>\n      <td>https://pll.harvard.edu/course/data-analysis-l...</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>High-Dimensional Data Analysis</td>\n      <td>A focus on several techniques that are widely ...</td>\n      <td>https://pll.harvard.edu/course/data-analysis-l...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>Analyzing Data with Python</td>\n      <td>In this course, you will learn how to analyze ...</td>\n      <td>https://www.edx.org/course/analyzing-data-with...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"# Important Notes\n\n* Original Source: https://www.kaggle.com/code/shtrausslearning/nlp-edx-course-recommendations\n* DeepSeek AI for original base which also calls the document embeddings for the input\n* I have added comments to better study and understand the code as a base to build off of\n* Instead of directly matching to a course index in the dataset which limits the use of the model\n\n# Todo (to better understand and be able to present on this topic)\n\n* Study cosine similarity\\\n* Word2Vec and stopwords/lemmatization\n\n# Improvements\n\nreshaped corpus as list instead of series, increased context window, ","metadata":{}}]}